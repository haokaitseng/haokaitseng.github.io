[{"categories":["Data Science","Polio","Vaccine"],"contents":" This post presents my research proposal for my MSc thesis: \u0026ldquo;Predicting the rate of Acute Flaccid Paralysis in different settings to support polio surveillance and elimination\u0026rdquo;.\nYou will learn why non-polio Acute Flaccid Paralysis (NPAFP) is important in support of polio eradication. The current challenge involves interpreting the AFP indicator that exceed the targeted levels. Potential data sources and modelling methods are raised to fill this knowledge gap. Aim and Objectives Research Aim To investigate and model the mechanisms underlying the notification of the key polio surveillance indicator - NPAFP rates in endemic and outbreak settings.\nResearch Objectives Review and consolidate existing evidence about the possible aetiologies of AFP in population aged less than 15. Identify the most informative predictive features for NPAFP rates in WPV-1 endemic countries and a selection of cVDPV outbreak countries. Building on the potential causal mechanism of AFP, modelling the expected NPAFP rates at both national and subnational levels. Background Polio Today Since the global efforts initiated in 1988, wild poliovirus has been very close to global eradication. Endemic transmissions of wild poliovirus type 1 (WPV-1) is restricted to certain regions in Afghanistan and Pakistan. There are also episodes of circulating vaccine-derived poliovirus (cVDPV), mostly notified in World Health Organisation African region (AFRO).\nThe WHO Global Polio Eradication Initiative (GPEI) sets the gold standard for detecting cases of poliomyelitis. The key indicator, the sensitivity of surveillance, is defined at least one case of non-polio AFP should be detected annually per 100,000 population aged less than 15 years. This is the minimum level for certificating a standard surveillance system, which indicate the probability that polio infection will be detected given that infection is present in the population. To ensure higher sensitivity in endemic regions and during polio outbreaks, the NPAFP rate should be two per 100,000 and three per 100,000, respectively (GPEI, 2021).\nAFP Notification AFP is characterized by repaid onset of gait disturbance, weakness, or trouble coordination in one or several extremities. The symptoms can progress to maximum severity within 10 days, frequently encompassing weakness of the muscles of respiration and swallowing. Every AFP case, as a result, poses a clinical emergency. It requires immediate neurologic examination to narrow the differential diagnosis, often involving electrophysiologic studies (Marx et al., 2000).\nPoliomyelitis is not the only cause of AFP. There many other causes, including Guillain-Barre syndrome, non-polio enterovirus, other neurotropic viruses, and acute traumatic sciatic neuritis. These potential causes of AFP are often associated with anatomic-morphologic changes or specific pathophysiologic mechanisms. Confirmation of either polio or NPAFP can only be achieved through collecting and testing of stool specimens from AFP cases within the Global Polio Laboratory Network (Tangermann et al., 2017). In other words, appropriate testing AFP, regardless of its presumed etiology, is an integral component of polio surveillance (Marx et al., 2000).\nFrom a macro perspective, the reporting of NPAFP may be associated with multiple factors within a sequence of events. These events include: (1) the necessity for a susceptible individual to be effectively exposed to the pathogens or causes mentioned above, (2) onset of symptoms, (3) seeking healthcare (accompanied by parents), (4) notification as AFP, (5) collection of stool specimens, (6) sample transportation, and (7) laboratory examination (Tangermann et al., 2017).\nAcross these sequence of events, factors such as dwelling environment (related to climate, sanitation, and access to healthcare services), susceptibility (related to immunity and underlying prevalence), strengths of the surveillance system (related to technical, laboratory ,human, and financial resources) may play crucial roles. For instance, Pakistan and India‚Äôs NPAFP rates have been observed as having some association with polio vaccine uptakes and polio cases, respectively (Dhiman et al., 2018; Molodecky et al., 2017). Besides, factors associated with an increase risk of poliovirus outbreaks have also been identified (O‚ÄôReilly et al., 2017). The interactions between polio campaigns and health systems were also illustrated through a causal loop diagram (Neel et al., 2021). Nevertheless, there remains a limited understanding and approach to quantify the associations between AFP notifications and various factors throughout the continuum of surveillance events, let alone establishing causal inference.\nChallenge The current gold standard of NPAFP rate to define a well-operating poliovirus surveillance system might be challenged. First, from the perspective of certification, zero-reporting doesn\u0026rsquo;t necessarily imply the absence of the underlying (latent) numbers of polio cases in a population. For example, an incorrect declaration of polio elimination almost occurred in Nigeria in 2016, following a track record of 730 days polio-free (Adamu et al., 2019; Bell, 2019).\nSecond, in response to outbreaks, a cross-country study indicates that maintaining a high rate of NPAFP is essential to timely detection of cVDPVs outbreaks (Auzenbergs et al., 2021). It is critical for community health workers in outbreak regions to know how effectively the AFP surveillance systems monitor and identify cases, coupled with environmental surveillance.\nThird, concerning international movements, no country can be exempt from the risk of imported polio cases. A WPV-1 confirmed case was reported in Malawi in 2017, which was genetically linked to WPV-1 transmission in Pakistan (2022). This underscores the ongoing risk of international spread until the objective of global polio eradication is attained. Countries that fail to report NPAFP rates after certification may require assessment.\nStatistics According to the WHO‚Äôs open data (Figure 1), it is observed that in 2000, the NPAFP rate falling within the range of 1 to 2 per 100,000 accounted for the largest share (43%) among the reporting countries. Over the years, there has been an increase in the proportion exceeding 2 per 100,000, with 77% of countries‚Äô NPAFP rates surpassing this standard in 2023.\nDiving into the data distribution, the median NPAFP rate of the annually median from the reporting countries is 1.7 per 100,000. However, this century ‚Äòs maximum NPAFP rates by year range from 3.8 to 373.9 per 100,000. This wide range is accompanied by an increasing standard deviation in recent years. This right-skewed distribution of data poses a challenge to properly interpretate changes in NPAFP rates, as it reflects different strength of surveillance in different contexts. Notably, the aftermath of the COVID-19 pandemic could potentially shapes the healthcare landscape, as well as the polio surveillance systems (Niaz et al., 2023).\nNPAFP rate (2000-2023) Min Q1 Median Mean Q3 Max Annual Median 1.3 1.5 1.7 2.5 1.9 19.3 Annual Mean 1.4 1.9 2.3 3.8 2.8 37.2 Annual Maximum 3.8 9.2 15 30.4 22 373.9 Annual SD 0.8 1.4 2.2 4.5 3.4 53.6 Mission Building on the partnership with the GPEI (on behalf of WHO), this project uses GPEI‚Äôs database, originally owned by the United Nations Children\u0026rsquo;s Fund (UNICEF). The AFP data (including polio and non-polio cases) cover a comprehensive time (\u0026gt; 20 years) and space, including WHO AFRO, Eastern Mediterranean Region (EMRO), and Western Pacific Region (WPRO). For the purpose of polio eradication, this project‚Äôs data landscape focuses on the WPV-1 endemic countries, Afghanistan and Pakistan, coupled with cVDPV outbreak countries, such as Nigeria. Publicly available data will also be collected and analysed as potential predictors at national and subnational levels.\nThe added value of this project is to offer insight into the reconsideration of GPEI‚Äôs key surveillance indicator - NPAFP rate. This project can also contribute to the component of the Free From Infection (FFI) framework of the broad SPEC project. By understanding the sensitivity of the different components that make up the detection process, this project aims to answer what rate of NPAFP should be expected in the under-15 group, either for retrospective data analysis or for future projections. If study countries consistently reports zero polio cases for a certain period, with NPAFP reporting rate exceeding the expected NPAFP rate, this can serve as evidence of the successful interruption of poliovirus transmission.\nADDED VALUE: By assessing the target rates of reported NPAFP among the under 15 population in endemic regions, this project\u0026rsquo;s value lies in defining a well-operating surveillance system, and identifying regions at risk of under detection.\nFurthermore, through the comparison between reported and expected NPAFP rates, it can also identify the weakness of surveillance systems and informs resource mobilisation during different phases, including outbreaks, eradication, and post-certification. Therefore, within the framework of the Polio Eradication Strategy 2022-2026 facilitated by GPEI, this project has scientific importance in providing essential support for surveillance activities and certification outlined in the strategy\u0026rsquo;s timeline.\nMethods Outcome Measures The NPAFP rate per 100,000 in children aged less than 15, which is GPEI‚Äôs number of NPAFP cases divided by the annual under-15 population size according to national statistics.\nPredictors The absolute number of AFP cases is likely to vary substantially between populations due to a number of factors. Predictors to be assessed including:\nGeographical: (1) urban, rural, or conflict zone, (2) districts bordering, (3) temperature, (4) precipitation, (5) risk of diarrhea. Demographic: (1) population size: fewer than 50,000 children under 15 years of age may not detect AFP every year (WHO, 2022), (2) population density, (3) migration and movement (displacement), (4) socio-economic (poverty and barriers to access), (5) total births, (6) gender proportions. Surveillance and healthcare system: (1) healthcare services quality, accessibility, and affordability (out-of-pocket payment), (2) Electronic surveillance technology, (3) sensitivity of laboratory testing methods, (4) environmental surveillance, (5) number of SIA campaigns, (6) human resources of community health workers, (7) health financing, (8) performance assessment or reward for reporting, (9) unit of reporting (number of offices/hospitals), (10) pre-and-post COVID-19 pandemic. Biological: (1) non-polio enterovirus rate, (2) Guillain-Barr√© Syndrome prevalence, (3) polio confirmed cases and type. Immunisation: (1) OPV and IPV vaccination coverage, (2) OPV and IPV vaccines administered, (3) switch from tOPV to bOPV. Models The time interval within the scope of the method may be monthly, 6-month, and annually, whilst geographical scale may be applied to district, country, and continent level. A sequential process from risk exposure, probability of present AFP disease, seeking healthcare, notification, stool collection, sample transportation, to laboratory results will be considered throughout the analysis. The models to be implemented are as follows:\nMachine learning methods, which are robust to high dimensionality and potential dependencies between predictors (dependent on what kind of indicators can be obtained across all geographies). This may include penalised regression (Lasso and Ridge), tree-based methods (random forest), or super learner. These methods focus on learning complex and non-linear relationships. They can assist in subset selection and variables selection, given the wide range of variables in this project. They can adapt to intricate patterns but may be prone to overfitting, especially with limited data; hence it is crucial to find a bias-variance trade-off.\nRegression based approaches accounting for spatial and temporal dependence. This may include generalized additive models (GAMs), splines, autoregressive models, and Poisson mixed-effect model. These methods focus on parameter estimation based on assumed relationships, also allowing non-parametric fits with relaxed assumptions. Past values of the variable of interest may be considered. Coefficients in these models may directly represent the impact of each variable on the dependent variable.\nMethods to evaluate out-of-sample predictive ability of models. It serves as an validation purpose. Reference Adamu, U. S., Archer, W. R., Braka, F., Damisa, E., Siddique, A., Baig, S., Higgins, J., Sume, G. E., Banda, R., Korir, C. K., Waziri, N., Gidado, S., Bammeke, P., Edukugo, A., Nganda, G. W., Forbi, J. C., Burns, C. C., Liu, H., Jorba, J., . . . Bolu, O. (2019). Progress Toward Poliomyelitis Eradication - Nigeria, January 2018-May 2019. MMWR Morb Mortal Wkly Rep, 68(29), 642-646. https://doi.org/10.15585/mmwr.mm6829a3 Auzenbergs, M., Fountain, H., Macklin, G., Lyons, H., \u0026amp; O\u0026rsquo;Reilly, K. M. (2021). The impact of surveillance and other factors on detection of emergent and circulating vaccine derived polioviruses. Gates Open Res, 5, 94. https://doi.org/10.12688/gatesopenres.13272.3 Bell, R. (2019, November, 18). Day Zero: Inside Nigeria‚Äôs response to the 2016 polio outbreak. Bill \u0026amp; Melinda Gates Foundation. https://www.gatesfoundation.org/ideas/articles/nigeria-2016-polio-outbreak-response Dhiman, R., Prakash, S. C., Sreenivas, V., \u0026amp; Puliyel, J. (2018). Correlation between Non-Polio Acute Flaccid Paralysis Rates with Pulse Polio Frequency in India. International Journal of Environmental Research and Public Health, 15(8), 1755. https://www.mdpi.com/1660-4601/15/8/1755 GPEI. (2021). Interim Quick Reference on Strengthening Polio Surveillance during a Poliovirus Outbreak. Global Polio Eradication Initiative Retrieved from https://polioeradication.org/wp-content/uploads/2021/12/Quick-Reference_Strengthening-Surveillance-during-Poliovirus-Outbreaks_24-March-2021.pdf Marx, A., Glass, J. D., \u0026amp; Sutter, R. W. (2000). Differential Diagnosis of Acute Flaccid Paralysis and its Role in Poliomyelitis Surveillance. Epidemiologic Reviews, 22(2), 298-316. https://doi.org/10.1093/oxfordjournals.epirev.a018041 Molodecky, N. A., Blake, I. M., O‚ÄôReilly, K. M., Wadood, M. Z., Safdar, R. M., Wesolowski, A., Buckee, C. O., Bandyopadhyay, A. S., Okayasu, H., \u0026amp; Grassly, N. C. (2017). Risk factors and short-term projections for serotype-1 poliomyelitis incidence in Pakistan: A spatiotemporal analysis. PLOS Medicine, 14(6), e1002323. https://doi.org/10.1371/journal.pmed.1002323 Neel, A., Closser, S., Villanueva, C., Majumdar, P., Gupta, S., Krugman, D., Akinyemi, O., Deressa, W., Kalbarczyk, A., \u0026amp; Alonge, O. (2021). 30 years of polio campaigns in Ethiopia, India and Nigeria: the impacts of campaign design on vaccine hesitancy and health worker motivation. BMJ Global Health, 6, e006002. https://doi.org/10.1136/bmjgh-2021-006002 Niaz, F., Tariq, S., Rana, M. S., Nashwan, A. J., Fatima, I., Afzal, Y., \u0026amp; Tariq, R. (2023). The resurgence of polio: The effect of the Covid-19 pandemic on polio eradication. Ethics Med Public Health, 26, 100858. https://doi.org/10.1016/j.jemep.2022.100858 O‚ÄôReilly, K. M., Lamoureux, C., Molodecky, N. A., Lyons, H., Grassly, N. C., \u0026amp; Tallis, G. (2017). An assessment of the geographical risks of wild and vaccine-derived poliomyelitis outbreaks in Africa and Asia. BMC Infectious Diseases, 17(1), 367. https://doi.org/10.1186/s12879-017-2443-4 Tangermann, R. H., Lamoureux, C., Tallis, G., \u0026amp; Goel, A. (2017). The critical role of acute flaccid paralysis surveillance in the Global Polio Eradication Initiative. International Health, 9(3), 156-163. https://doi.org/10.1093/inthealth/ihx016 WHO. (2022). Standard operating procedures: responding to a poliovirus event or outbreak, version 4. W. H. Organization. https://iris.who.int/bitstream/handle/10665/363627/9789240049154-eng.pdf?sequence=1 This MSc summer project is under the SPEC (Surveillance Modelling to Support Polio Elimination and Certification) project work package 1: Surveillance Modelling, led by Dr. Kathleen O\u0026rsquo;Reilly and supervised by Dr. Emily Nightingale at LSHTM.\n","date":"2024-05-03T22:11:12+08:00","permalink":"https://haokaitseng.github.io/post/20240503_polio_proposal/","section":"post","tags":null,"title":"The Beginnig of the End: What Is the Expected Notification Rate of the Polio Surveillance Indicator?"},{"categories":["Vaccine"],"contents":"For poeple doing vaccination works, their world wareness day is not a single day - it\u0026rsquo;s a week, spanning from 24th to 30th April each year.\nThis year, WHO celebrate 50 years of the \u0026ldquo;Expanded Programme on Immunization (EPI)\u0026rdquo;.\nIn LSHTM\u0026rsquo;s Vaccine Centre (VaC), our world immunisation week (WIW) topic this year is \u0026ldquo;responding to outbreaks\u0026rdquo;. We want to highlight the collective action needed to protect people from outbreaks and vaccine-preventable diseases. This is the largest event series of the year, and we\u0026rsquo;ve spent several months meticulously planning activities to celebrate this week.\nAs a student liaison officer of VaC, I contributed in the following two projects - poster and podcast.\nPoster I used Inkscape to illustrate the key image for WIW - a little boy saying no to a virus, with a post-vaccinnation bandage and a VaC backpack. The blue theme is used in our daily newsletter and website deployment, in alignment with the school\u0026rsquo;s color policy. Podcast Serving as the student liaison officers of VaC, Ashna and I collaborated to record a podcast series with Ben Kasstan-Dabush. Ben is an Assistant Professor of medical anthropology at LSHTM, evaluating vaccine programme delivery amidst the COVID-19 pandemic, measle outbreaks, and poliovirus incidents within Jewish community. He has brilliant insights and critial thinking about vaccine engagement and the relationships that vaccine is embedded in. We had a excellent time interviewing him and gained a wealth of knowledge from both reading his research and engaging in conversation with him. Highly recommended!\n\u0026ldquo;Immunity is about relationships: outbreak response and vaccine engagement\u0026rdquo; Listen now for the trailer.\n\u0026ldquo;Immunity is about relationships: outbreak response and vaccine engagement\u0026rdquo; Listen now for the full episode.\nIn this episode, Assistant Professor Ben Kasstan-Dabush from the Department of Global Health \u0026amp; Development at LSHTM sits down with Student Liaison Officers Ashna Pillai and Hao Kai Tseng from the LSHTM Vaccine Centre to talk about vaccines and the relationships between parents, community, and health systems.\nBuilding on the fieldwork stories with Haredi Jewish families, Ben Kasstan-Dabush delves into his vaccine research around the religious communities and the complementary delivery pathways tailored for them.\nBen Kasstan-Dabush describes an outbreak as firefighting caused by a lack of investment. ‚ÄúHow do we sustain that money, so that we\u0026rsquo;re not in a problem of constant firefighting.‚Äù, he said. Unfortunately, the learning and models implemented during the COVID-19 pandemic have limited transferability to routine immunisation programmes.\nTake the measles outbreak in the UK for instance, Ben Kasstan-Dabush discusses the concept of the link between the declining vaccine coverage and chronic deprivation. Thinking about ‚Äúvaccine engagement‚Äù aids in understanding the complex relationships that vaccination is embedded in, where we should not lose sight of the particular political, economic, and social climate in which vaccines are delivered, alongside the ability and resources of our systems. Therefore, building resilience and flexibility into immunisation programmes is crucial for enhancing vaccine uptake.\nWhat do we need in outbreak management? How is deprivation linked with vaccine uptake? Why is it helpful to think about vaccine engagement? Together, Ben Kasstan-Dabush and the Student Liaison Officers will guide you through these questions, with a focus on the key lessons learned from COVID-19, measles, and poliovirus outbreaks.\nOther Events \u0026amp; Podcasts VaC hosts three events and other two podcasts during the WIW. Be sure not to miss them!\nüéà EVENTS\nüóì 23 April | Vaccine Centre Annual Lecture: Professor Dame Sarah Gilbert Development of vaccines against outbreak pathogens\nüóì 25 April | Community engagement for vaccination in humanitarian settings: A view from the field\nIdaraobong Ekanem, ‚ÄãIFRC / Nigeria Red Cross‚ÄØSofi Lazlo, MSF Nada Abdelmagid, LSHTM Mohamed Kahow, ‚ÄãSave the Children Somalia üóì 30 April | Health promotion and vaccination in the age of social media: insights from the frontline\n‚Äã‚ÄãNatalia Pasternak Taschner, University of S√£o Paulo, Brazil‚Äã Cherstyn Hurley, UKHSA Vishaal Virani, Head of UK Health, YouTube üìª PODCASTS\nüóì 22 April | Responding to polio outbreaks ‚Äì new vaccine, old foe\nEdward Parker, LSHTM Nick Grassly, Isobel Blake, and Laura Cooper, Imperial College London Ed Clarke and Dr Larry Kotei, MRC Unit in The Gambia at LSHTM üóì 24 April | The use of vaccines in outbreak response\nEd Newman, Nadine Beckmann and Sophie Everest, UK Public Health Rapid Support Team Nicholas Davies, LSHTM ","date":"2024-04-22T22:11:12+08:00","permalink":"https://haokaitseng.github.io/post/20240425_world_immunisation_week/","section":"post","tags":null,"title":"World Immunisation Week 2024"},{"categories":["Data Science","Vaccine"],"contents":" This group project is a collective effort, with contributions from my teammates Minn Thit Aung, Polly Nightingale, Simon Kent, and Xavier Dunn, listed alphabetically.\nThis post aims to:\nDetermine the the basic reproduction number (R0) of an hypothetical outbreak Assess the impact of various strategies for vaccination and school closures on accumulative cases and peak cases/timing Provide instructions for constructing a SEIR model using Berkeley Madonna Offer simple R code for converting a ggplot into a GIF Setting the Scene Many countries have recently experienced the first wave of an influenza pandemic caused by the strain HuNz. Now, there are rumours that in a distant country N, the second wave of the pandemic is just starting, and more infections have been reported so far.\nThe Ministry of Health in country P has become concerned and has called an emergency meeting to discuss the next steps, assuming that the transmissibility of the virus increases by 50% between the first and second waves.\nIf you were a group of modelling experts in the country P, how do you prepare for this emergency meeting and inform the Ministry of Health the decision-making process?\nModel Structure The type of model used is a deterministic model with an SEIR framework, short for Susceptible-Exposed-Infectious-Removed. This model uses differential equations to estimate the change in populations over time (rate) in the various compartments, assuming static patterns.\nNotably, we incorperate age-dependednt mixing, which means the transmission probability/parameter are different between age groups: children-to-children, adults-to-children, children-to-adults, and adults-to-adults.\nFitting the First Wave The information already known during the first wave includes: population (182,091 children and 369,909 adults), infectious period (2 days), latent period (2 days), fraction of symptom (60%), fraction of reporting (15%), vaccine efficacy (25%), susceptibility (50% first-wave infected individuals are fully protected against the second strain). Also, through the surveillance system, we\u0026rsquo;ve known the cummulative weekly number of reported infections for children and adults.\nWe must ascertain the basic reproductive number (R0) to inform our modelling for the second wave. Using the information mentioned, we apply the Curve Fit function in the Berkeley Madonna to fit our model to the first-wave data. Here comes the the optimal age-dependet transmission parameters: Œ≤1, Œ≤2, and Œ≤3 in the Who-Acquire-Infections-From-Whom (WAIFW) matrix. Œ≤ is the per capita rate at which two individuals, in this case age-speceficly, come into effective contact per unit time.\nTo derive the R0 in the first wave, Next Generation Matrix is used along with a simulation process. Briefly, based on the initial assumed conditions, this method simulate the dynamics of the disease spread over time, i.e. from one generation to the next generation. Once the simulation has reached a steady state (equilibrium), we can estimate R0 using the observed data. Finally we get 1.47 as our R0 in the first wave, which is not far from the historical R0 of influenza in the 20s century.\nModelling for Second Wave No Intervention Assuming an initial case of one child infection (seeding) in our country and 100% fraction of reporting, we multiply the first-wave WAIFW matrix by 1.5 because the transmissibility of the second wave is believed to be 50% higher. The Berkeley Madonna SEIR model produces cruves of cumulative number of symptomatic cases of children, adults, and all population.\nThis is a no-intervention scenario (scenario 1). It is estimated that 28.7% children, 22.3% adults, and 24.4% total population will experience symptoms due to the new influenza strain.\nInterventions Due to a global shortage, we have no stocks of antivirals and hope that closing schools and vaccination will help limit the spread of the infection. However, the vaccines supplied for the second wave are limited and we are expected to receive enough doses for 50% of the population. The available vaccine doses will be given to children, with any remaining doses being given to adults.\nThe school-closure intervention will shut down the school for four weeks once the true proportion of children who have experienced symptoms during the second wave has reached 0.5%, which is called the school-closure threshold. We suppose that the Œ≤1 will be 60% lower during the school-closure period, i.e. the Œ≤1 need to be multiplied with 0.4.\nIn the global environment of the Berkeley Madonna model:\rb1_school_open = 5.83845e-6 b1_school_closure = 2.33538e-6\rb1 = if ((time\u0026gt; 53) and (time\u0026lt;83)) then b1_school_closure else b1_school_open where on the 54th day the true proportion of children who have experienced symptoms hit the threshold\rNow we can try the modelling for four basic scenrios:\nScenario 1: No intervention Scenario 2: School Closure Scenario 3: Vaccination for 100% children and 25.39% adults (=50% total population) Scenario 4: Vaccination and School Closure, scenario 2 and 3 combined Owing to interventions, the proportion symptomatic in the total population are 24.1%, 19.8%, and 19.4% in scenarios 2, 3, and 4, respectively. It can be observed that the impact of school closure is limited, compared to vaccination programme.\nIn terms of flatting the curve and delaying the peak, similarly, the vaccination programme performs better than school closure does. The most effective strategy for controlling the outbreak involves a combination of vaccination and school closure measures (scenario 4).\nThe R code for this animation is included in the appendix at the bottom.\nIt is worth examining the Net Reproductive Number (Rn) at various point of time, calculated as the product of the transmission rate (Œ≤) with the susceptible population and the duration of infectiousness using the next generation matrix. In the begining of the scenario 1\u0026amp;2, the Rn is 1.59. However, at the first day of the school closure in scenario 2, the Rn decreases to 1.155.\nWith the collective protection from vaccination and acquired immunity from the first wave, the Rn in the begining of the scenario 3\u0026amp;4 is 1.32. Upon the implementation of school closure in scenario 4, Rn becomes 1.164. The Rn reaches a critical value of one at the peak of each curve.\nSensitivity Analysis To explore the potential strategies in response to the outbreak, we come up with the following advanced scenarios:\nScenario 5: Longer School closure (3 months) Scenario 6a: Adjsut the threshold of school closure from 0.5% to 0.2%. Scenario 6b: Adjsut the threshold of school closure from 0.5% to 1%. Scenario 7: Equal vaccine distribution: distribute the same doses vaccines to children and adults. Scenario 8: The strain is 200% higher transmissible than the first wave Scenario 9: Adjust the fraction of reporting from 100% to 60% Vaccination Distribution: Equity or Equality? We regard scenario 3 as a equitable strategy for vaccine distribution, as it prioritize individuals who are more vulnerable to the disease and have a higher transmission rate (where Œ≤1 \u0026gt; Œ≤2 \u0026gt; Œ≤3).\nIn contrast, scenario 7 is a equal strategy for vaccine distribution. This is a equal allocation due to the same weight (number of vaccine doses) given to both groups of people.\nIt can be observed that an equitable vaccine distribution program proves more effective in controlling outbreaks compared to equal distribution models, this is due to the equity-driven resource allocation favoring people with higher transmission rates (Œ≤1).\nThresholds for School Closure Apart from proportion symptomatic, peak cases and peak timing are also critical indicators for controlling an outbreak.\nScenarios Peak Cases Peak Day Prop. Symp. 8-Vac\u0026amp;200%Trans 20,917 52 40% 7-Vac (equal) 9,597 65 29% 1-No interv. 6,077 87 24% 2-Clos.(0.5%) 5,298 113 24% 3-Vac 3,243 140 20% 6a-Vac\u0026amp;Clos.(0.2%) 3,077 155 20% 4-Vac\u0026amp;Clos.(0.5%) 2,839 156 19% 6b-Vac\u0026amp;Clos.(1%) 2,499 157 19% 9-Vac\u0026amp;60%Rep. 1,946 140 20% 5-Vac\u0026amp;Clos.(3m) 1,462 151 17% In this table, we sort the scenarios by the peak cases, and we focus on three scenarios with vaccination and different thresholds for school closure (scenario 6a, 4, and 6b). These three scenarios have similar peak timing and proportion symptomatic. However, the higher the threshold we set, the lower the peak cases we have.\nIn other words, as long as we know the surge capacity of the healthcare system, we can manipulate the threshold to flatten the curve, preventing the health care systems from overwhelming patients.\nConclusion Key Finding Choosing from four basic scenarios (1-4), we recommened the vaccination only strategy to our Ministry of Health to mitigate the surges in influenza cases.\nIn scenario 4, the combined effects of vaccination and school closure result in the largest reduction of symptomatic cases (20.6%) compared to scenario 1 as the reference. However, closing schools may delay the peak of cases, while the significance depends on whether burden to health services, given zero mortality in this context.\nCost to society of school closure may result in disrupting children\u0026rsquo;s education/causing parents to miss work. This highlights the importance of considering the Incremental Cost Effectiveness Ratio (ICER) in the modelling.\nLimitations This hypothetical study has some limitations due to the assumptions. First, no births or deaths are included in model. Second, we assume the latent and infectious periods in the second wave are the same as virus in first wave. Third, proportions of cases showing symptoms is assumed the same in adults and children, and the fraction of reporting is not possible to reach 100% in the realworld settings.\nRecommendations First of all, it\u0026rsquo;s important to collect more data to conduct a more comprehensive economic evaluation of control measures, which is the highlighted in a panel discussion at LSHTM - The use of modelling to inform decision-making in an emergency: lessons from COVID-19. Assessing changes in behavior throughout an outbreak in real-time can be challenging as they are difficult to predict in advance. Besides, assessing the effects on healthcare service is critial. It may also be useful to conduct a cohort/surveillance that we study for seroprevalence through outbreaks. The Ministry of Health may try to combine other non-pharmaceutical interventions, e.g. social distancing, wearing mask, personal hygiene.\nThis group project was originally intended for a group presentation of the the Modelling and the Dynamics of Infectious Diseases module at LSHTM, with contributions from Minn Thit Aung, Polly Nightingale, Simon Kent, and Xavier Dunn, listed alphabetically.\nAppendix # The gganimate package demonstrates how to make the ggplot in the scenario 1-4 into a GIF\r#The data structure should be: a day of newly reported cases in each row, and each column is a scenario\rlibrary(gganimate)\rplot_object \u0026lt;- ggplot() +\rgeom_line(data=df1,aes(x=Time,y=Scenario1),color=\u0026quot;#088199\u0026quot;,size=0.7)+\rgeom_line(data=df1,aes(x=Time,y=Scenario2),color=\u0026quot;purple\u0026quot;,size=0.7)+\rgeom_line(data=df1,aes(x=Time,y=Scenario3),color=\u0026quot;#Ca0020\u0026quot;,size=0.7)+\rgeom_line(data=df1,aes(x=Time,y=Scenario4),color=\u0026quot;#b8e186\u0026quot;,size=0.7)+\rgeom_text(data=df1,aes(x=Time, y=Scenario1 + 1.5,label=paste('S1')), color = \u0026quot;#088199\u0026quot;)+\rgeom_text(data=df1,aes(x=Time, y=Scenario2 + 1.5,label=paste('S2')), color = \u0026quot;purple\u0026quot;) +\rgeom_text(data=df1,aes(x=Time, y=Scenario3 + 1.5,label=paste('S3')), color = \u0026quot;#Ca0020\u0026quot;)+\rgeom_text(data=df1,aes(x=Time, y=Scenario4 + 1.5,label=paste('S4')), color = \u0026quot;#b8e186\u0026quot;)+\rtheme(panel.grid.major = element_blank(),\raxis.line = element_line(colour = \u0026quot;black\u0026quot;),\rpanel.background = element_rect(fill = \u0026quot;transparent\u0026quot;),\rplot.title=element_text(hjust=0.5)) +\rscale_x_continuous(breaks=seq(0,350,25))+\rlabs(y=\u0026quot;Daily New Reported Cases\u0026quot;,x = 'Time (Day)',title = \u0026quot;Outbreak Dynamics of Influenza Strain HuNz\u0026quot;)\rprint(plot_object)\rplot_object_transition \u0026lt;- plot_object + transition_reveal(Time) # make static into dynamic\ranimate(plot_object_transition, #save the GIF\rfps = 50, #frame rate\rduration = 1.5, #speed\rwidth = 1800, height = 865, #dimension\rrenderer = gifski_renderer(loop = FALSE,\u0026quot;My_animation.gif\u0026quot;),\rres= 100)# accuracy every fold\r","date":"2024-03-30T22:11:12+08:00","permalink":"https://haokaitseng.github.io/post/20240327_modelling_flu/","section":"post","tags":null,"title":"Equity vs. Equality: Modelling Vaccine Distribution Strategies for Outbreak Response Decision-Making"},{"categories":["Data Science"],"contents":" How do you apply time-to-event analysis to compare the impact of different prescriptions on death?\nThis article examines the survival function of two prescriptions using Kaplan-Meier and Cox models in an electronic health records (EHR) setting. EHR data are powerful real-world data. They are conducive to time-to-event analysis owing to the characteristic of sequential visits to primary and secondary care services. Take UK\u0026rsquo;s OpenSAFELY for instance, this secure, transparent, and open-source platform provides an Trusted Research Environment (TRE) for National Health Service (NHS) EHR data analysis, which supported urgent research into the COVID-19 emergency.\nSetting the Scene Building on a hypothetical EHR data, this project aims to understand the impact of a prescription of proton pump inhibitor (PPI) versus a prescription for a histamine H2-receptor antagonist (H2RA) on all-cause mortality. To extract analysis data from various datasets of EHR and code lists, I use the following eligible criteria to define the study cohort:\nPPI and H2RA prescription with first prescription timeframe from 17 April 1997 to 17 April 2017 the first prescription is after patient\u0026rsquo;s registration at general practice (GP) plus one year the first prescription is after the patient‚Äôs 18th birthday. The study follow-up begins at the first prescription for PPI or H2RA, and it ends at the first of:\ndeath (event of interest) transfer out of GP end of study (17 April 2017), i.e. administrative censoring Considering confounding effects, 10 potential confounding variables from the cohort are also examined: (1) age at prescription, (2) gender, (3) ethnicity, (4) Index of Multiple Deprivation (IMD), (5) body max index (BMI), (6) calendar year of first description, (7) diagnosis of gastric cancer prior to prescription, (8) gastro-oesophageal reflux disease (GERD) in the 6 months prior to prescription, (9) peptic ulcer in the 6 months prior to prescription, and (10) number of consultations in the year prior to prescription.\nNotably, addressing missing data is an essential part of EHR data analysis. I adopt a strategy where patients\u0026rsquo; birth dates are assumed to be on the 15th of June in the given birth year. Additionally, for BMI, I prioritize my-self-calculated BMI over those reported by GPs, while ensuring that the derived BMI values fall within an acceptable and realistic range of heights and weights.\nTime-to-event Data For the purpose of survival analysis, I define the length between index date (at first description) and end date (either death, censoring due to out of GP, or censoring due to end of study) as the days in the study.\nFrom the perspective of exposure, the median length of follow-up is 4 years in PPI group and 9 years in H2RA group, respectively. The distribution of the length of follow-up is strongly right-skewed in the PPI group, whereas such distribution is not observed in the H2RA group.\nLength of Follow-up by Prescription/Death in Years Subgroup N Median IQR PPI 12,984 9 4.5-13.4 H2RA 61,816 4 0.5-6.1 Death 13,741 3.4 0.3-5 Alive 61,059 5.2 0.8-8.6 Disaggregated by outcome, those who are alive in the cohort period have longer follow-up (median 5.2 years), in comparison of the median 3.4 years for those who died.\nKaplan-Meier Method To investigate the crude survival probability across two exposure groups, the non-parametric estimate of Kaplan-Meier is used. The probability of surviving 5 years or more is 0.888 (95% confidence interval, CI: 0.883-0.894) in H2RA group, whereas the probability of surviving 5 years or more is 0.796 (95% CI: 0.792-0.8) in PPI group.\nThe survivor functions in H2RA group are always higher than those in PPI group. As time goes by, the difference in survivor functions between the two groups increases, from 0.057 at year 1, to 0.109 at year 10, to 0.132 at year 19.\nBy using log-rank test, an overall lower survival probability in PPI group is confirmed (the chi-square statistic is 556 on 1 degree of freedom, p-value \u0026lt; 0.05), in comparison to H2RA group.\nCox Regression Univariable Model By fitting a univariable Cox proportional hazard model, a semi-parametric method, the log hazard ratio estimate is 0.52. The estimated hazard ratio is 1.68, which means the hazard for all cause death is increased by 68% in the PPI group relative to the H2RA group. The 95% CI (1.61-1.76), not covering null, indicates a strong evidence against the null hypothesis of no association between exposure and the hazard for death.\nNote that the Cox Proportional Hazard (PH) assumption implies the hazard ratio measuring the effect of any predictor, i.e. prescriptions in this case, is constant over time.\nMultivariable Model Considering potential confounding, I examine whether the effect estimate, e.g. odds ratios in logistic regression, changes substantially after adding each candidate confounding variable in the Cox model. Also, for the purpose of survival curve estimation, certain non-confounding varaibles are selected into the multivariable Cox proportional hazard model.\nFurthermore, to investigate whether the functional form for the continuous variable age is appropriate in the multivariable model, I calculate the Martingale residuals for age and number of consultations. However, it can be observed from the LOESS lines that direct employing a linear term for these continous varaible is appropriate.\nIn the final multivariable Cox PH model adjusting seven selected confounding ( below), the log hazard ratio estimate is 0.093. The estimated hazard ratio is 1.098 (95% CI: 1.049-1.150), meaning the hazard for all cause death is increased by 9.8% in the PPI group compared to the H2RA group. Compared to the univariable model, the effect of PPI is reduced in the multivariable model, yet still significant.\nh(t‚îÇX) = h0 (t)exp‚Å°{ Œ≤1*X{PPI}+Œ≤2*X{calendar period}+Œ≤3*X_{IMD person}+Œ≤4*X{gender} +Œ≤5*X_{ethnicity}+Œ≤6*X{recent GERD}+Œ≤7*X{number of consultations}+Œ≤8*X{age} Xi:exposure for individual i (i=1,‚Ä¶,n); ti:death or censoring time for individual i; Œ¥:indicator of death (1)or censoring (0).\nAssessing the PH Assumption I use the scaled Schoenfeld residual to assess the assumption of the multivariable Cox PH model. The null hypothesis in this test is that the corresponding Œ≤(t) coefficient does not vary over time, indicating that the proportional hazards assumption holds for that variable.\nIt can be observed that the hazard ratio is changing over time in some variables. The global Chi-square statistic in the Schoenfeld residual is 211 (p-value \u0026lt; 0.05), indicating this model in general didn‚Äôt follow the proportional hazard assumptions. For instance, in the beginning of follow-up, PPI‚Äôs hazard is similar to H2RA‚Äôs hazard, but the log hazard ratio of PPI is lower at later times.\nExtended Cox Model Since the assumption of the Cox PH model is violated, I use extended Cox model to accommodate the non-proportionality. This approach allows the hazard ratios to be dependent on time, i.e. interacting with time. After splitting cohort data into five-year chunks according to the adjusted years of follow-up in the study, we can see the hazard ratios of PPI over H2RA in 4 periods.\nIn the extended model, the overall hazard ratio is 1.165 in PPI group relative to H2RA group. However, using PPI-period 1 (year 0-5) as reference in the extended Cox model, the estimate of hazard ratio is 0.946 in the PPI-period 2 (year 5-10) group compared to H2RA group during the same period, with other covariate holding constant.\nEstimating Survival Curve To apply the extended Cox model to hypothetical patient profiles, imagine four scenarios:\nA man aged 50 in the white ethnicity group, with no co-morbidities and in the most deprived group. A man aged 50 in the white ethnicity group, with recent diagnosis of Gastroesophageal reflux disease (GERD) prior to prescription and in the least deprived group. As in 1. but for a woman. As in 2. but for a woman. I plot the Cox survival curves in four scenarios by four periods, given this extended model is built upon time-dependent effect for the exposure. It can be observed that males (solid line) have lower survival functions compared to females (dashed line). In each scenarios during period 1, 2, and 3, the survival functions is lower in PPI group compared to H2RA group. However, in the period 4 (year 15 to 20), H2RA seems to have a higher risk of death, where its survival curve is under the PPI group.\nConclusion EHR data are often used for survival analysis, either in parametic (Weibull), non-parametric (Kaplan-Meier), or semi-parametric (Cox) model. This article examines the observations which are times at which death occurs, in comparison of two prescriptions. Based on the extended Cox regression, hazard ratio gets increased by 16.5% in PPI group relative to H2RA group, whereas the hazard ratio is changing over time.\nThis article has been adapted from the assessment of the Analysis of Electronic Health Record module at LSHTM.\n","date":"2024-03-23T22:11:12+08:00","permalink":"https://haokaitseng.github.io/post/20240322-survival-analysis/","section":"post","tags":null,"title":"Survival Analysis in Electronic Health Records Data"},{"categories":["Data Science","Machine Learning"],"contents":" In this article, we will explore the following topics:\nUsing regularized method (Lasso) for predictive variable selection Tuning hyperparameters for tree-based methods Employing the weighted sum of weak learners for boosted classifier Comparing prediction performances and predictors importance Basic Methods Inmagine you possess a dataset comprising 30 biomarker varaibles with 5000+. How would you use it to predict patient\u0026rsquo;s remission status, i.e. remission or active disease? One common approach that may cross your mind is the logistic regression, as illustrated below:\nlogit(p) = Œ≤0‚Äã+Œ≤1‚ÄãX1‚Äã+Œ≤2‚ÄãX2 ‚Äã+‚Ä¶+Œ≤30*‚ÄãX30\nIn addition to logistic regression, we can apply t-test to inform the normalised difference between remission\u0026rsquo;s binary outcome.\nAlso, regarding collinearity, it worths looking into the correlations across the predictive variables. Through visual inspection, we can identify some strong correlations, such as alt \u0026amp; ast, ymph_percent * neut_percent in the correlations plot.\nRegularized Mothod Lasso regression is a regularized method in machin learning that performs both variable selection and regularization. It can identify the insignificant or unimportant variables as zero coefficients. The variable selection and shrinkage effect are strong with the penalty parameter¬†Œª. With the increase of Œª in the below, the number of non-zero coefficients reduces from 30 to 0, where the lines are shrinkage paths.\nTo find an optimal hyperparameter Œª, I used an automated 10-fold cross validation on Lasso. The lowest error is observed at the log Œª¬†of -8.11. However, I want to choose the Œª¬†at which error is within 1 standard error of the minimal error, i.e. the 1 se criterion. To balance the bias-variance trade-offs, log Œª of -4.66 is preferred because it provides similar predictive performance compared to log Œª¬†of -8.11. This is also much easier to interpret with less variables, and less likely to overfit to noise in the training data.\nAfter tuning the Œª, there are 12 no-zero beta coefficients remaining in the Lasso laerner. The complexity of the model is hence reduced.\nTree-based Methods CART As a supervised learning approach, a single Classification And Regression Trees (CART) is a useful algorithm, which is used as a predictive model to draw conclusions about a set of observations. At each node, the tree grows in a binary direction, initiating the first split based on whether the hgb is less than 13 or not. In the node where hgb \u0026lt; 13, it is calssified that 67% of the patients has a status of remission.\nBagging With more than one decision trees, our learning model can be become ensemble, which means the kearning process is made up of a set of classifiers. The bootstrap aggregation, also known as bagging, is the most well-known ensemble method. Using bagging, a random sample of data in the training set is selected with replacement and then trained independently. Finally, taking the average or majority of those estimates yield a more accurate prediction.\nIn our training data, I loop over 10 to 500 trees for bagging. This help me to determine the number of trees required to sufficiently stabilize the Root Mean Squared Error (RMSE). With 340 trees, the model achieves the lowest RMSE and demonstrates a tendency to stabilize thereafter.\nRandom forest Random forest algorithm is an extension of bagging, as it uses both bagging and feature randomness to create an uncorrelated forest of decision trees. In random forest, a selection of a subset of features ensures low correlation among decision trees, which can reduce over fitting and increase accuracy.\nTo training a random forest algorithm, five hyperparameters should be considered:\nSplitting rule Maximum tree depth/ Minimum node size Number of trees in the forest Sampling fraction Number of predictors to consider at any given split (mtry) To find an optimal mtry, here I utilize 10-fold cross validation for random search and grid search. In random search, when you have 8 predictors to consider at any given split, you have the highest accuracy. In grid search, the optimal mtry is 10, with a higher Kappa, indicating a better classifier, considering the marginal distribution of the remission status.\nWith regard to sampling fraction, reducing the sample size can help minimize between-tree correlation. As different sets of sampling fractions are tried, either with or without sampling replacement, the minimal out-of-bag (OOB) RMSE is observed at 90%. This suggests that optimizing predictions can be achieved by drawing 90% of observations for the training of each tree.\nGoing through these searches of hyperparameters with minimal OOB RMSE, the tuned random forest requires at least 340 trees to grow, with 10 mtry and 90% sampling fraction (with replacement). Gini impurity is adopted for the split rule, which is suitable for the scope of classification.\nmtry 10 10 8 8 Sampling fraction OOB RMSE (replacement) OOB RMSE (non-replacement) OOB RMSE (replacement) OOB RMSE (non-replacement) 100% 0.5175449 0.5165891 0.5139516 0.5237148 90% 0.5137112 0.5173061 0.5165891 0.5194512 60% 0.5192133 0.5144322 0.5192133 0.5170672 Overall, in evaluating prediction performance, it is evident that the tuned random forest exhibits the lowest RMSEs among the tree-based methods.\nLearner OOB misclassification error RMSE (validation set) Single CART - 0.58809 340 bagged trees 0.2641463 0.5058941 Random forest (default) 0.2661 0.5049165 Random forest (tuned) 0.2639 0.5058941 Here the importance of the predictors are presented. The feature with the highest importance in the random forest is lymph_percent.\nAdaboost Adaptive boosting, known as adaboost, is also an ensemble learning method that combines multiple weak learners sequentially to adjust the weights of training instances based on their classification accuracy. Adaboost is usually applied in binary classification, where misclassified instances are given higher weights. These weak models are generated sequentially to ensurethat the mistakes of previous models are learned by their successors.\nWith a step size of 0.1, my optimal number of boosting iterations are 323, remainining 19 predictors in the generalized linear model. This number indicates the best balance between model performance (error) and computational efficiency.\nModels Comparison The specificity, sensitivity, Positive Predictive Value (PPV), Negative Predictive Value (NPV) of the tuned random forest model are all higher than the Logistic, LASSO, and Adaboost in the validation set, i.e. 20% of the data that is not used for training. The Kappa of 48% as of random forest means a fair agreement.\nLeaner Accuracy Kappa Sensitivity Specificity PPV NPV Logistic Regression 69.27% 37.67% 78.11% 59.20% 68.57% 70.35% Lasso 68.77% 36.43% 80.33% 55.60% 67.34% 71.27% Random forest 74.41% 48.33% 79.59% 68.50% 74.22% 74.65% Adaboost 68.97% 36.91% 79.59% 56.87% 67.77% 70.98% We particularly investigate the area underneath the ROC (AUC) of Lasso and random forest. For random forest, the AUC of 0.808 suggests a reasonable ability to discriminate between the remission status, better than Lasso‚Äôs AUC of 0.741. Moreover, there are statistical difference (Z = 6.6253, P \u0026lt; 0.05).\nFinally, let\u0026rsquo;s dive into the importance of the predictors. There are 6 common predictors selected by Lasso and Random forest. Hbg, mch, lympch_percent are the most impactful among five methods, where mch hgb and lymph percent had large normalised differences in the previous T-test analysis. In the figure below, the underlined predictors that are unique to either Lasso or random forest exhibit a distinct pattern in the previous correlation pairs.This is a characteristic of Lasso penalty: it will typically pick only one of a group of correlated predictor variables to explain the variation in the outcome.\nConclusion Random forest (74.41%) has better accuracy on the prediction for the validation data, surpassing logistic regression, Lasso, adn Adaboost. Besides, regarding AUC, random forest (0.741) has a good ability to discriminate between the remission and active disease.\nIn terms of predictor importance, among the 12 predictors selected by Lasso learner, 6 of them are also selected in the top 12 predictors identified by the random forest, indicating their importance. Therefore, through using these important predictors, fitting a tuned random forest model on their biomarkers can support the predicting of remission status.\nIn collaboration with ChatGPT, this article has been adapted from the assessment of the Machine Learning module at LSHTM, with thanks to lecturers Pierre Masselot, Alex Lewin, and Sudhir Venkatesan.\n","date":"2024-02-10T22:11:12+08:00","permalink":"https://haokaitseng.github.io/post/20240210-machine-learning-lasso-random-forest/","section":"post","tags":null,"title":"Predicting Remission Status in Healthcare: A Comparative Analysis of Lasso, Random Forest, and Adaboost Machine Learning Models"},{"categories":["Data Science"],"contents":" What can you learn from this article?\nUnderstand the concepts of data linkage, especially deterministic linakge. Address linkage error in the conjunction of MIMIC III (served in a postgreSQL database) and ODK database. Employ R to design the Extract, Transform, and Load (ETL) pipeline. Use Quarto document to generate a report in PDF format. Concepts of Data Linkage In a data scientist\u0026rsquo;s typical day, the merge/join function is an inevitable task. Data quality must be secured through linkage within one dataset (\u0026lsquo;internal linkage\u0026rsquo;) or across multiple datasets.\nAccording to the OECD Glossary of Statistical Terms, data linakge means a merging that brings together information from two or more sources of data with the object of consolidating facts concerning an individual or an event that are not available in any separate record.\nIn situations of uncertainty, there might be an linkage error, i.e. misidentifying relationships that belong to the same entity. Notably, linkage error doesn\u0026rsquo;t adhere to an binomial distribution (0 or 1); rather, it resembles a spectrum ranging from high agreement to high disagreement, along with matching possibilities influenced by quality of matching variables.\nSource: James Doidge, 2023\nIn order to evaluate the performance of data linkage, we can build a matrix for the link-match classification. In theory, we wish our data to achieve a ~100% sensitivity (proportion of matches that are linked), or recall, while in parralel keeping the specificity (proportion of non-matches that are not linked) high as well. To achieve these goals, three methods for data linkage are widely used, including deterministic linakge, probalistic linkage, and machine learning.\nMatch (records from the same entity) Non-match (records from different entities) Link True match False match Non-link Missed match True non-match Source: Collaboration in Research and Methodology for Official Statistics, European Commission\nI will apply the deterministic linkage method in this article. A set of predetermined rules is used to identify patterns as links or non-links. For instance, the high degree of certainty/agreement required for deterministic linkage is achieved through a unique identifier for an entity, such as NHS number. This method may allow a small amount of preconceived typographical error; however, the limitations of this method lie in the event of lower quality matching variables or handling large numbers of matching variables.\nA scenario during COVID pandemic Let\u0026rsquo;s dive into a practical scenario where data linkage proves invaluable. Suppose you are a data analyst in a UK hospital, where data is captured in the MIMIC III database and ODK database. Your hospital management has asked you to generate an executive report synthesising recent patient data from MIMIC III, survey data from ODK, and national statistics for COVID-19. Besdies, to address surges in COVID-19 cases, you should be able to regularly generate this report, with potential changes to the prototype.\nWhat\u0026rsquo;s your strategy on this mission?\nDBI First, a database interface (DBI) is required to initialize the extract, transform, load (ETL) workflow. DBI package can help connect my R to database management systems (DBMS).\nAs MIMIC III is served in a PostgreSQL database, I chose RPostgres package to help me build the connection from PostgreSQL to R. Notably, RPostgres package can better capture the variables with timestmaps, comepared to the PostgreSQL package. A few lines of postgreSQL code are executed here to retrieve the specific data I need.\nI then use ruODK package to configure and download data from ODK Central to R.\nAs for national statistics, I use the download.file() function in base R to get a CSV file from the data.gov.uk.\nData Linkage Now, I are about to merge the data from MIMIC III and ODK for further cleaning, transforming, filtering, and analysis. Based on deterministic linkage method, I assume/regard the subject_id as our reliable agreement for matching between two datasets.\nAfter utilizing R\u0026rsquo;s merge() for an inner join, I want to examine the quaity of the data linkage by introducing two additional matching variables: age at admission and gender.\nLinkage error in age Substantial variation in differnce in ages is noted following the linkage. The distribution of age difference for 25% to 75% of patients shows a deviation of within one year, which is deemed acceptable owing to rounding. Nevertheless, noticeable errors are evident in the minimum (-39) and maximum (303) age differences.\nDifference in ages between MIMIC III and ODK:\nMin. Q1 Median Median Q3 Max. -39 -1 1 33.95 1 303 To address this issue, we can exclude observations that surpass the expected lifespan. Subsequently, consult the data provider to determine which data source is more reliable regarding age entry. You can either rely on a single dataset as the definitive age or eliminate observations with significant deviations in ages.\nLinkage error in gender Let\u0026rsquo;s move on to the gender variable. There seems a bit mismatches, such as \u0026ldquo;Female-Man\u0026rdquo; and \u0026ldquo;Male-Woman\u0026rdquo;. Again, you can decide either omit all observations with mismatches in genders, or rely on a single dataset as the definitive gender.\nComparison of gender categories between MIMIC III and ODK:\nMIMIC III / ODK Man Woman Trans Non-binary Female 6 2620 4 4 Male 2953 2 8 10 It is also noteworthy that individuals identifying as trans and non-binary are retained in my merged data frame. This inclusion is crucial as gender minority groups may feel uncomfortable when presented with a table offering only binary options for female and male. In other words, for me, they are not linkage error; instead, \u0026lsquo;it\u0026rsquo;s a defect in the gender variable of MIMIC III.\nAfter handling the linkage error, I then apply some exploratory data analysis (EDA) to privde summary satatistics for our patients. This data processing is not covered in this article.\nQuarto Finally, following data anaylsis, I use Quarto, the next generation of R Markdown released in 2022, to play as our publishing system.\nYou can smoothly do all the programming in a single qmd file for Quarto document. Alternatively, you can also save your output from your previous R scripts somewhere, and then open a new qmd file to read and print your outputs. Knitr::kable and kableExtra package is highly recommended for generating decent LaTeX tables in a PDF format.\nConclusion In short, investigating the matching variables may provide an indication of confidence in the link. In my scenario, I minimized data linkage error by initially agreeing on subject_id, and then stepwisely and partially agreeing on age and gender.\nAdditionally, processing data from various sources is achieved by using R to execute the ETL pipeline, ensuring a reproducible workflow for synthesizing a report as below.\nThis article has been adapted from the assessment of the Health Data Management module at LSHTM. With thanks from James Doidge who introduced the data linkage topic in the Thinking Lika A Health Data Scientist module.\n","date":"2024-01-06T22:11:12+08:00","permalink":"https://haokaitseng.github.io/post/20240101-data-linkage-etl-mimic/","section":"post","tags":null,"title":"Minimizing data linkage error in an ETL pipeline using R: an intersection of MIMIC III and ODK database"},{"categories":null,"contents":"Hi! My name is Hao Kai Tseng. I am currently a graduate student of Health Data Science Programme at the London School of Hygiene \u0026amp; Tropical Medicine (LSHTM).\nI acquired my BSc Public Health from the National Taiwan University in 2016. I have gained experience in the field of infectious diseases through my work in both a research institute and a governmental health sector Taiwan.\nI am interested in policy implementation and evaluation related to infectious diseases. The COVID-19 pandemic has heightened my focus on strengthening society\u0026rsquo;s capacity for pandemic prevention, preparedness, and response. Besides, I am actively engaged in assessing TB patient costs for WHO‚Äôs End Tuberculosis Strategy.\nAs a Student Liaison Officer of the Vaccine Centre at LSHTM, my career aspirations revolve around streamlining data pipelines in support of immunization initiatives.\nAs a gay, promoting equity is my mission.\nIn an attempt to pull my skillsets to the cloud, this blog aims to offer practical applications and inspirations that give the push you need to explore the realms of public health and data science.\nI wish you good luck in your search!\n","date":"2023-12-21T20:18:54+03:00","permalink":"https://haokaitseng.github.io/about/","section":"","tags":null,"title":"About Me"},{"categories":["Vaccine"],"contents":" What can you learn from this article? An experimental cohort study design for policy evaluation, where countries made the move from a two-dose to single-dose schedule for national HPV vaccination programmes since 2023.\nIntroduction Since the first licensing of the Human Papillomavirus (HPV) vaccine in 2006, evidence has been emerging showing that single-dose schedules provide comparable efficacy to the conditional regimens, i.e. two or three doses. In 2022, a review of World Health Organization (WHO) Strategic Advisory Group of Experts on Immunization (SAGE) concluded that a single-dose HPV vaccine delivers solid protection against HPV. Consequently, there have been 16 countries that adopt SAGE\u0026rsquo;s recommendation of single-dose schedule in their national immunization programmes in 2023, including the UK [Figure 1].\nThis study aims to assess the non-inferiority of the real-world impacts in single-dose HPV vaccination programmes with regard of herd immunity and paradigm shift. Method This research is designed as a prospective and closed cohort study with a 20-year follow-up.\nSource Population Age: adolescent females aged 12 to 13 in 2023-24 in 16 study countries, i.e. age eligible to their national HPV vaccine program. Inclusion: get at least one dose of HPV vaccine and undergo screening in the follow-up period. Exclusion: those who migrate out of the study countries. Exposure The final vaccination status, categorized into two and three doses of HPV vaccines, is considered as two distinct exposures. Single-dose HPV vaccination serves as the reference group (non-exposure). Outcome Regarding the disease progression [Figure 2], in the first decade, this study defines precancer as the preliminary outcome, including Cervical intraepithelial neoplasia (CIN) 2+ and Adenocarcinoma in situ (AIS).\nCervical cancer is investigated as the secondary outcome over the last decade. Three kinds of methods are used for screening testing, including pap smear test, liquid based cytology (LBC) test, and visual inspection with acetic acid (VIA). Data Collection Follow-up continues until the diagnosis of cervical cancer (or precancer), death, or the end of 2043. The rationale for 20-year follow-up is the highest incidence rates being in the 30 to 34 age group in the UK, that will be the end of their follow-up.\nData integration is streamlined through annual data linkage across five sources from each country, including population immunization registry, cervical screening registry, death registry, national migration record, and regional socio-economic status.\nStatistical Analysis The demographic characteristics are depicted through the mean (¬± standard deviation) and counts (percentage).\nThis study uses Cox proportional-hazard regression, adjusted for sexual orientation and socio-economic index, with age as the time axis to estimate hazard ratios (with 95% Confidence Intervals, CIs) of cervical cancer (or precancer) stratified by country according to their vaccine doses.\nNon-inferiority is defined when the difference in hazard ratios is less than a 5% deviation from 1.\nRESULT (HYPOTHETICAL) Take UK for instance, the cohort include 305,307 vaccinated females. Of these, 259,511 (85%) received single dose, 39,690 (13%) received two doese, and 6,106 (2%) received three doses. Their mean age completed vaccination is 12.6, 13.8, and 15.3, respectively.\nOverall, the average number of screens is more than 2. The years between complete vaccination and screening, sexual orentation, and socio-economic index are detailed in Table 1.\nThe difference in the incidence rate ratio of three subgroups is negligible (1 dose 6.84, 2 doses 6.51, and 3 doses 6.42, per 100,000 person-years). The adjusted hazard ratio was not significantly lower for 2+ dose groups compared to single-dose women (2 doses 0.96 (95% CI 0.87-1.05) and 3 doses 0.95 (0.86-1.05)), indicating the non-inferiority of single-dose schedule [Table 2].\nOf 16 study countries, 14 single-dose HPV vaccination programmes achieve non-inferiority. (The findings from countries outside the UK are omitted.) DISSCUSION Strengths This research exhibits four strengths. First, the substantial sample size enhances the generalizability of findings. Second, Geographical comparisons are attainable thanks to multi-country data sources. Third, data are reliably obtained, as they are routinely updated in country\u0026rsquo;s immunization and screening programs. Last but not least, the final disease outcome, i.e. cervical cancer, is used as the study measurement, surpassing previous studies reliant on short-term outcomes, such as HPV persistent infection.\nLimitations and bias However, this research is constrained by its assumptions of not stratifying results according to vaccine brands or screening methods, the later may lead to misclassification due to diverse sensitivity and specificity of the testing. Unregistered or incorrect record of doses may also cause non-differential misclassification of the exposure. Such information bias is towards the null.\nWith regard to selection bias, the willingness of screening may be influenced by the final vaccination status. Notably, the exclusion of females who have not been vaccinated in the defined source population is essential to prevent such selection bias.\nTrade-offs When it comes to inferiority, this study\u0026rsquo;s emphasis lies in the trade-offs aspect. On the side of single dose, higher immunization coverage can be obtained, which is conducive to herd immunity. Besides, the number of cases averted will be more appealing to policy makers from a prospective of public health. Not to mention the benefit of efficient implementation and reduced costs.\nOn the side of 2+ doses, the relative risks exhibit a somewhat lower magnitude. With regard of the waning immunogenicity, some modelling studies suggest that some of the single dose girls need a catch-up dose to obtain sufficient immunity in population. CONCLUSION (HYPOTHETICAL) Single-dose HPV vaccination demonstrates comparable efficacy compared to 2+ doses in 14 out of the 16 study countries\u0026rsquo; programmes, suggesting that a shift to single-dose schedule is suitable for cervical cancer prevention.\nThis article has been adapted from the poster, originally created as part of the assessment for the epidemiology module at LSHTM. I express sincere gratitude to Professor Neil Pearce for his exceptional teaching.\n","date":"2023-12-15T22:11:12+08:00","permalink":"https://haokaitseng.github.io/post/20231216-hpv-single-dose-vaccination/","section":"post","tags":null,"title":"Assessing the Non-inferiority of the Single-dose Human Papillomavirus Vaccination Schedule: A Hypothetical Multi-country Cohort Study"},{"categories":["Data Science"],"contents":" This article delivers two key insights:\nAdvantages of applying UK GDPR in research planning. Five approaches to safeguard data protection in lung cancer patient interviews. Setting th Scene The need of assessing the Quality of Life (QoL) in patients with lung cancer undergoing chemotherapy has been increasing. After treatment, patients may experience breathlessness or fatigue, along with potential challenges in their daily and occupational functioning. These side effects of chemotherapy consistently rank as a common complaint among patients. By using the validated QoL questionnaire from the European Organisation for Research and Treatment of Cancer, a hypothetical research project aim to summarize the QoL state among a cohort of patients in a hospital in the UK. Hopefully it can benefit the treatment of choice.\nHowever, concerns regarding data protection were brought up in a management meeting, with the focus on data confidentiality.\nMany patients consenting to participate in the study have uncertainty about their personal data processing, particularly in relation to sensitive questions. How do you lawfully and comprehensively tackle the data protection issue in a patient survey?\nData Governance in GDPR To manage such risks, the GDPR can be one of the best solutions that is inetegrated into the research planning and implementations. Implementing this information governance rules can yield numerous benefits, encompassing aspects such as safeguarding individual rights and freedom, fulfilling lawful obligations, and gaining hospital\u0026rsquo;s competitive advantages.\nConversely, non-compliance with GDPR may cause research failure, distress to individuals, fines and penalties, and damage to hospital\u0026rsquo;s reputation.\nGiven GDPR‚Äôs seven key principles below, I propose five approaches that center on the principle of integrity and confidentiality to mitigate information governance risks and remove doubts regarding data security. Procedures and policy for data processing security With regard to security in data processing, transfer, and storage, it can be achieved through technical procedures and organisational policy, such as encryption, pseudonymization, access control, and audit.\nInformation technology (IT) security remediation Through employing tools for reviewing IT security, system vulnerabilities can be identified and mitigated, along with fortified protection against potential security threats and cyber security events.\nProtocols for notifying a personal data breach Protocols need to be developed to respond to a personal data breach event, ensuring that the investigation and reporting are completed within 72 hours.\nAppointing a data protection officer This role‚Äôs responsibility is to oversee, monitor, and document operations related to data processing, applying extensive knowledge of data protection practices.\nA centralised area designated for data storage and processing To minimize the risk of data leak, data processing is exclusively and physically performed on these dedicated desktops in an office.\nFor more detailed you can refer to the GDPR‚Äôs Data Protection and Impact Assessment Table in the end of this post\nRecommended Approaches To balance between risks presented by processing personal data and research utility, I propose endorsement of the first three approaches as a selection of strategies for this study due to following reasons. First, they follow GDPR‚Äôs principle of integrity and confidentiality, a priority particularly valued by your patients.\nSecond, the advantages inherent in these approaches are substantial. For instance, the first and second approach can minimize the likelihood of negative events, such as unauthorized access or data breach; the third approach then serves as a response to such negative events.\nThird, the consequences of not implementing these approaches would be intolerable when weighed against their disadvantages, since a lack of robust safeguards for data protection can result in confidentiality risks, violation to regulations, and erode trust among patients.\nLastly, the estimated residual level of information governance risks (impact and probability) for the first three approaches are lower compare to the remaining approaches. A data protection officer (fourth approach) is considered more suitable for a large-scale study; a centralized area for data processing (fifth approach) runs a risk of accidental data corruption.\nConclusion Research planning can incorporate GDPR to help make trade-offs in data/information governance risks. While each GDPR‚Äôs principle is equally important, I recommend three approaches that can strengthen the compliance to the principle of integrity and confidentiality. By establishing procedures and policy, implementing IT security remediation, and generating protocols for notification, this hypothetical study can have appropriate safeguards in place to process data safely.\nFurthermore, I believe the assessment of QoL can provide the opportunity to improve QoL and symptom burden management of lung cancer patients with chemotherapy drugs. Therefore, we can not only accelerate research progress but also address confidentiality and regulatory requirements in our scope of research.\nData Protection and Impact Assessment Table What approach could be taken to reduce risk? What actions would this involve? What are the advantages and disadvantages of these actions for research? Approach 1: Procedures and policy for data processing security (1) Data processing involves the practice of protecting information from unauthorized access and corruption during the entire research lifecycle. (2)It encompasses robust encryption and pseudonymization of personal data, while in parallel ensuring confidentiality, integrity, and resilience of processing systems. (3)Regular audit and monitoring are required to promptly detect and address any anomalies or potential data breaches. (4)Encrypted data transfer is implemented, and data storage and network security are ensured through essential measures on physical hardware. (1) Advantages: (1-1)Implementing security procedures and policies helps mitigate the risks of accidental or unlawful destruction, alteration, loss, and unauthorized access. (1-2)It not only complies with Article 32 of the GDPR but also adheres to the accountability principle of the GDPR, as the security logs and documentation can be used to demonstrate compliance. (2) Disadvantages: Enforcing access controls could introduce complexity and potentially decrease efficiency within the research project. Approach 2: IT security remediation (1)IT security remediation is an actionable set by detecting and protecting against potential security vulnerabilities or cyber security events, such as unauthorized access or disclosure due to non-encrypted transmission of data. (2)It identifies existing and scheduled mitigations for security issue, and rank likelihood of the issue occurring given existing or scheduled mitigations. (3)It updates existing security and antivirus software and strengthens IT infrastructure to ensure mitigations and controls are in place. (1) Advantages: (1-1)Cybersecurity remediation can help manage risks and intercept IT security threats. This approach aligns with the National Cyber Security Centre (NCSC) Cyber Assessment Framework (CAF) guidance. (1-2)By identifying security concerns, it indirectly adheres to the integrity and confidentiality principle of the GDPR. (2)Disadvantages: Procurement and management of security software entails ongoing expenses. Approach 3: Protocols for notifying a personal data breach (1)In response to personal data breach, protocols and internal procedures should be well-planned, including pulling the facts, contain the breach, access the risk, and report it without delay, and act to protect affected patients. (2)After having become aware of personal data breach, the research team should notify the issue to the Information Commissioner, no later than 72 hours. (3)LSHTM‚Äôs Research Ethics Committees should also be notified when any breach of the study protocol or the principles of Good Clinical Practice has been identified. (1) Advantages: (1-1)According to Article 33 of the GDPR, reporting a personal data breach in a timely manner (\u0026lt;72 hours) can avoid fine (up to ¬£8.7 million or 2 per cent of turnover) and penalties. (1-2)It meets the principle of lawfulness, fairness and transparency, accountability, and integrity and confidentiality in the GDPR. (1-3)A comprehensive procedure can save time to respond to an event of personal data breach and communication strategy (Article 34 of GDPR). (2)Disadvantage: Documented protocols and procedures are needed, along with essential training sessions for the research team. Approach 4: Appointing a data protection officer (1)The data protection officer is designated on the basis of data protection laws (GDPR) and practices for confidentiality. (2)The data protection officer is involved in all issues which relate to the protection of personal data, including regular and systematic monitoring of data subjects. (3)The data protection officer manages and maintains records of data analysis logs, as well as input and output activities within the designated area. (1)Advantages: (1-1)Compliance with regulations is regularly and systematically monitored, which aligns with the Article 37 of the GDPR and the principle of integrity and confidentiality and accountability of GDPR. (1-2)There is a contact point on issues relating to processing and protecting personal data. (2)Disadvantages: (2-1)The scope of this research is insufficient to warrant the role of a data protection officer, since systematic monitoring of data subjects is not conducted on a large scale. (2-2) Research budgetary allocation will be required to hire a data protection officer. Approach 5: A centralised area designated for data storage and processing (1)A structured set of personal data, including electronic health records, is stored in the filing system of the desktops in the information management department at the hospital. (2)Only members from the research have access to the research eligible patients‚Äô personal data. (3)Data processing and analysis are exclusively and physically performed on these dedicated desktops. (1)Advantages: (1-1)It ensures that data remains confined to these systems and cannot be exported, minimizing the risk of data leak. (1-2)It provides protection against unauthorised processing of personal data, which aligns with the principle of integrity and confidentiality from the Article 5 of the GDPR. (2)Disadvantages: (2-1)There is a risk of accidental loss or corruption in the event of destruction or damage to the area of centralized data. (2-2)Remote work is not available. In collaboration with ChatGPT, this article has been adapted from the assessment of the Thinking like a Health Data Scientist module at LSHTM.\n","date":"2023-10-30T22:11:12+08:00","permalink":"https://haokaitseng.github.io/post/20231030-data-governance/","section":"post","tags":null,"title":"Optimizing Data Protection: Leveraging Information Governance Principles from GDPR into Research Planning"},{"categories":["Data Science"],"contents":"This year, London home rental prices hit record as demand outstriped supply, with the average tenant now being asked to pay a whopping ¬£2,500 a month for a new let.\nWithin this rental market, individuals seeking short-term accommodations encounter greater challenges. My roommates and I was looking for a house/flat for co-renting with a 6-month tenancy, and we put in a significant effort throughout the entire month of August by searching and making inquiries about over 170 properties before finally settling down. Using Python in Visual Studio Code, I hereby analyze the data in our list of properties, which might provide an insight for your search and budget.\nWhat you will learn in this article:\nTrade-off between comunicating time and rent. Key factors that determine rent. Strategies to find your property. Photo by Jo√£o Barbosa on Unsplash\nTrade-off Between Comunicating Time and Rent We browsed websites such as OpenRent, RightMove, Spotahome, and Zoopla during our search. We documented the features of 174 properties, capturing details including price per calendar month, tenancy, number of bedrooms, number of bathrooms, maximum number of tenants, location (zone), and comunicating time to my School (London School of Hygiene and Tropical Medicine) measured using Google Maps.\nFirst, the majority of rental properties in the market typically require a minimum one-year tenancy commitment, whereas our preference is for a shorter-term tenancy of more or less 6 months, with the option to extend if everything proceeds smoothly. Hence, among the targeted properties that specified their tenancy requirements, 81% state their acceptance of a minimum 6-month tenancy.\nHere I provide a overview of our data by price, communicating time, and the number of bedrooms. The range of rent is between ¬£1,850 to ¬£4,500, while the range of communicating time is from 17 to 67 minutes.\nIf you are also sensitive to both cost and time, you can observe a noticeable pattern through simple linear regression. It suggests that you need to invest approximately ¬£19 in order to gain an additional minute of time saved on your commute to school.\nTo validate the assumption of normality and homoscedasticity in the regression model, I make QQ-plot and random clouds. They seem pretty good.\nI also use K-means clustering algorithm to find the most suitable number of clusters according to rental costs. There is a substantial disparity between the outcome obtained using the elbow method and the Silhouette Score. The elbow method indicates that 4 clusters would be optimal, aligning somewhat with the established property zones. In contrast, the Silhouette Score suggests for a more fine-grained segmentation into 9 groups.\nKey Factors That Determine Rent Aside from communicating time, many factors also contribute to our living qualities. When conducting a multiple linear regression analysis, I identify that several variables significantly impact rent:\nProperty Zone: Choosing to reside in Zone 2 instead of Zone 1 can result in a savings of ¬£319, while opting for Zone 3 over Zone 2 can lead to a savings of ¬£102. Number of bedrooms: Acquiring an additional bedroom is associated with an increased cost of ¬£384. Number of bathrooms: An additional bathroom comes with an added expense of ¬£62. On the other hand, certain factors appear to have less influence on rent, including directional location of the property, maximum number of tenants, and minimum tenancy.\nStrategies to Find Your Property When seeking short-term accommodation in London it\u0026rsquo;s imperative to dedicate substantial effort to locate and secure your perfect property within this highly competitive rental market. In the following sections, I will outline three useful strategies that can enhance your search and help you save valuable time:\n1. Establish Your Financial Parameters and Objectives Begin by determining your budget constraints and the anticipated duration of your stay. Identify essential amenities that align with your preferences, such as a two-bathroom layout, laundry facilities, access to a rear garden, or parking availability. Additionally, be sure to specify your desired move-in date.\nIf your plan involves a shorter tenancy, be prepared for the possibility of residing further away from the center of London. Generally, properties locate in Zone 3 or the outskirts of London are more amenable to short-term tenancies. In addition, many landlords may require you to make an upfront payment of the total rent, if you lack a job, a reliable financial history, or references.\n2. Utilize Appropriate Online Platforms Consider exploring channels such as Spotahome, OpenRent, and various Facebook groups for your search. Spotahome operates in a manner similar to Airbnb, offering a comprehensive online process prior to your arrival. OpenRent may have a little landlords open to short-term tenancies, especially those looking to rent out properties located in remote or less competitive areas.\nHowever, exercise caution in Facebook rental groups, as scams can be a concern.\nMainstream websites like RightMove often feature properties gear toward long-term rentals, so they may not align with your short-term needs.\nLastly, don\u0026rsquo;t hesitate to contact a local agency to seek their assistance in locating a suitable property. Nestify is a good choice, since all of their properties are available for 3-9 months.\n3. Act Swiftly In the fast-paced environment, it\u0026rsquo;s essential to act swiftly to secure your desired house. You should regularly check rental websites that I mentioned for new listings everyday. Hot properties get inundated with inquiries. Send a detailed introduction to the landlord or agency.\nOnce a viewing is confirmed, whether in-person or virtually, make your decision promptly, I mean, in hours! Stay proactive throughout the process of paying deposit and signing contract. Delaying the process could result in the property being offered to other interested parties.\nConclusion I exemplify the know-how for searching for short-term accommodation London. Drawing on evidence-based analytics, this article offers data-driven insights into several factors influencing the cost of short-term rentals.\nNavigating the complex world of real estate in London can be daunting, but this article aims to anchor readers in their decision-making process.\nWishing you the very best of luck in your search!\nThis article is also published on Medium„ÄÇ\n","date":"2023-09-09T22:11:12+08:00","permalink":"https://haokaitseng.github.io/post/20230907london-rent-cost/","section":"post","tags":null,"title":"Navigating Short-Term Accommodation Search in London"},{"categories":["Essay"],"contents":"‰Ω†Áü•ÈÅìÔºåÂè∞ÁÅ£ÊòØÂÖ®ÁêÉÂèóÂ¢ÉÂ§ñÂÅáË®äÊÅØ‰æµÊìæÊúÄÂö¥ÈáçÁöÑÂúãÂÆ∂ÔºåËÄå‰∏îÂ∑≤Á∂ìËü¨ËÅØÊ¶úÈ¶ñ10Âπ¥ÂóéÔºü\nÊú¨ÊñáÈÅ∏Âè∞ÁÅ£ÁöÑÁîüÂåñÂØ¶È©óÂÆ§ÁÇ∫‰æãÔºåÊè≠Èú≤‰∏ÄÂÄãÂ¢ÉÂ§ñË≥áË®äÊìçÂºÑËàáÂπ≤È†êÁöÑÊâãÊ≥ï„ÄÇ\nË¨†Ë®ÄÁöÑÂâç‰∏ñ Âæû2020Âπ¥COVID-19Áñ´ÊÉÖ‰ª•‰æÜÔºåÂú®Áï∂ÊôÇÁöÑTwitter(ÁèæÁ®±X)Ê∏†ÈÅì‰∏äÔºåÂ∞±ÊµÅÂÇ≥‰∏ÄÂÄãË¨†Ë®ÄÊòØÔºåÁæéÂúãÂú®ÂÖ®‰∏ñÁïåË®≠ÁöÑÁîüÂåñÂØ¶È©óÂÆ§Ë¢´Èô∏Á∫åÊõùÂÖâÔºåÂåÖÂê´Âè∞ÁÅ£ÁöÑ10Â∫ßÂØ¶È©óÂÆ§Ë©≥Á¥∞ÂêçÁ®±„ÄÅÂú∞ÂùÄ„ÄÅËÅØÁµ°Ë≥áË®äÁ≠â„ÄÇ\n‰ΩÜÈÄôË®äÊÅØÂ∑≤ÊúâCofactsÁúüÁöÑÂÅáÁöÑÂíåMyGoPenÈó¢Ë¨†ÔºåÊåáÂá∫„ÄåÁæéÂúãÂú®Âè∞Ë®≠ÂØ¶È©óÂÆ§ÂÅöÁîüÂåñÊ≠¶Âô®ÊàñÁ†îÁ©∂Â§ßË¶èÊ®°ÊµÅË°åÁóÖ„ÄçÂ±¨ÊñºÈô∞Ë¨ÄË´ñÔºå‰ºÅÂúñÁÖΩÂãïËàáÂàÜÂåñ„ÄÇ\nÂè∞ÁÅ£ÈÄôÂâáË¨†Ë®ÄÁöÑÂâçË∫´ÔºåÊòØ‰æÜËá™‰øÑÁÉèÊà∞Áà≠ÁöÑÂÅáË®äÊÅØ„ÄÇ\n‰øÑÂúãÊõæÊåáÊéßÁæéÂúãÂú®ÁÉèÂÖãËò≠ÈñãË®≠ÁîüÂåñÂØ¶È©óÂÆ§Ôºå‰øÑÁÉèÊà∞Áà≠ÈñãÊâìÂæåÔºåÈÇÑÁ∑äÊÄ•Èä∑ÊØÄËá¥ÂëΩÁöÑÁóÖÂéüÈ´î„ÄÇ‰ΩÜÂØ¶ÊÉÖÊòØÔºåÁæéÂúãÂú®Êà∞ÂâçÂ∞±Êé®ÂãïÂú®ÁÉèÂÖãËò≠ÁöÑÂÖ¨Ë°õÂèäÁîüÁâ©Â®ÅËÑÖÊ∏õÂ∞ëË®àÁï´Ôºå‰∏¶ÈùûÁ†îÁôºÁîüÁâ©Ê≠¶Âô®Ôºå‰∏îÈä∑ÊØÄÂè™ÊòØÈÅøÂÖçÂØ¶È©óÊ®£Êú¨ËêΩÂÖ•‰øÑËªçÊâã‰∏≠„ÄÇ\nÂèØË¶ãÈÄôÊ¨°ÁöÑÈô∞Ë¨ÄË´ñÁâàÂúñÊì¥Â§ßÔºåÊää‰øÑÁÉèÊà∞Áà≠ÁöÑË¨†Ë®ÄÂ∑®Á∂≤ÂºµÂà∞Âè∞ÁÅ£ÁöÑ‰∏äÁ©∫„ÄÇ\nË¨†Ë®ÄÁöÑ‰ªäÁîü ‰ªäÂπ¥7ÊúàÔºåËÅØÂêàÂ†±Áç®ÂÆ∂Â†±Â∞éÁæéÊñπË¶ÅÂè∞ÁÅ£ÈñãË®≠P4ÂØ¶È©óÂÆ§Á†îÁôºÁîüÁâ©Êà∞Âäë„ÄÇÂâçÁ´ãÂßîÈõ∑ÂÄ©‰∫¶Âú®‰∏≠Â§©Êñ∞ËÅûÁöÑÁØÄÁõÆ‰∏äË°®Á§∫ÔºåÂõ†ÁÇ∫Âè∞ÁÅ£‰∫∫ÂèØ‰ª•‰ª£Ë°®ÂÖ®‰∏≠Âúã‰∫∫ÁöÑDNAÔºåÊâÄ‰ª•ÁæéÊñπÂú®Ê≠§Á†îÁôºÁîüÁâ©Êà∞ÂäëÊòØÂç±Èö™ÁöÑ„ÄÇ\nÁ∏±‰ΩøÂúãÈò≤ÈÉ®„ÄÅÂúãÂÆâÂ±Ä„ÄÅÂ§ñ‰∫§ÈÉ®„ÄÅÁæéÂúãÂú®Âè∞ÂçîÊúÉÁ´ãÂàªËÅ≤ÊòéÊ≠§ÂÇ≥ËÅûÈùû‰∫ãÂØ¶ÔºåÂè∞ÁÅ£ÊõæÁ∞ΩÁΩ≤„ÄåÁ¶ÅÊ≠¢ÁôºÂ±ï„ÄÅË£ΩÈÄ†„ÄÅÂÑ≤Â≠ò„ÄÅÂèñÂæóÊàñ‰øùÊúâÁîüÁâ©ÂèäÊØíÁ¥†Ê≠¶Âô®‰∏¶ÈÅøÂÖçÂÖ∂ÂèØËÉΩÂºïÁôº‰πãÊØÄÊªÖÂÖ¨Á¥Ñ„ÄçÔºåÊïÖ‰∏çÁ†îÁôºÁîüÁâ©Êà∞ÂäëÔºå‰∏îÂè∞ÂåóÂú∞Ê™¢ÁΩ≤ÂæåÁ∫åÊñº9Êúà5Êó•Ë™çÂÆöÊâÄË¨Ç„ÄåÂçóÊµ∑Â∑•‰ΩúÊúÉË≠∞Á¥ÄÈåÑ„ÄçÂØ¶Â±¨ÈÄ†ÂÅáÔºåÂåÖÊã¨‰ΩøÁî®‰∫ÜË®±Â§ö‰∏≠ÂúãÂºèÁî®Ë™ûÁ≠â„ÄÇ‰ΩÜÈõ∑ÂÄ©ÁöÑÁñëÁæéÁâáÊÆµË¢´ËΩâÂÇ≥ÂÜçË£ΩÔºåÊúÄÂÜçÂä†‰∏äÂæÆÂçöÂ§ßVÁéâÊ∏äË∞≠Â§©(ÂØ¶ÁÇ∫‰∏≠ÂúãÂ§ÆÂª£Êóó‰∏ãÁöÑËá™Â™íÈ´îÂìÅÁâå)ÁöÑÊé®Ê≥¢Âä©ÁÄæÔºåËÆìËÅ≤ÈáèÈÅîÂæÆÂçöÁöÑ135Ëê¨ÂΩ±ÁâáËßÄÁúã‰∫∫Ê¨°Ôºö\n„ÄåÁúüÊ≠£Ë¢´ÁäßÁâ≤ÁöÑÂà∞Â∫ïÊòØË™∞Ôºü„Äç ‚îÄ‚îÄ ÁéâÊ∏äË∞≠Â§©„ÄäÁã¨ÂÆ∂Êä´Èú≤Âè∞ÊπæÁîüÁâ©ÂÆûÈ™åÂÆ§ÂàÜÂ∏É„Äã(2022/8/16)\nÁéâÊ∏äË∞≠Â§©‰∏ç‰ΩÜÊöóÊåáÂè∞ÁÅ£‰∫∫Ê∞ëÂ∞±ÊòØÁæéÂúãËàáÂè∞ÁÅ£ÊîøÂ∫úÂãæÈÄ£‰∏ãÊúÄÂ§ßÁöÑÁäßÁâ≤ËÄÖ(Âõ†ÁÇ∫Âè∞ÁÅ£P2Á≠âÁ¥ö‰ª•‰∏äÂØ¶È©óÂÆ§Â§öÂú®‰∫∫Âè£Á®†ÂØÜÂçÄÂÑ≤ËóèÁóÖÊØí)ÔºåÈÇÑÂ∞ç‰∏≠Âúã‰∫∫Ê∞ëÊÅ´ÂöáÂè∞ÁÅ£ÁóÖÊØíÁöÑÂ®ÅËÑÖ(Âè∞ÁÅ£ÂØ¶È©óÂÆ§Â§ö‰ΩçÊñºÈù†Ëøë‰∏≠ÂúãÁöÑË•øÂçäÈÉ®)ÔºåÈÇÑÈôÑ‰∏äÁπ™ËÅ≤Áπ™ÂΩ±ÁöÑË≠âÊìö(ÂúãÈò≤ÈÉ®È†êÈÜ´ÊâÄÂ¢ûÂä†ÁöÑÈ†êÁÆóÊòØÁÇ∫‰∫ÜÂª∫P4ÂØ¶È©óÂÆ§Ôºå‰ª•ÂèäÈ†êÈÜ´ÊâÄÁñë‰ººÂãïÂúüÂâçÂæåÁöÑÁ©∫ÁÖßÂúñ)„ÄÇÈô∞Ë¨ÄË´ñ„ÄÅÁñëÁæéË´ñ„ÄÅËàáË™áÂºµÊèèËø∞ÁöÑÊâãÊ≥ïÂèØË¶ã‰∏ÄÊñë„ÄÇ\nÂú®FacebookÁöÑÁπÅÈ´îÂ≠óÁ§æÁæ§Ôºå‰πüÁôºÁèæ‰∏Ä‰∫õÁï∞Â∏∏Êìç‰Ωú„ÄÇÂë®ÊõâÂΩ§ËΩâË≤º‰æÜËá™TiktokÁöÑÁü≠ÂΩ±ÁâáÔºåÁàÜÊñôÁæéÂúãË¶ÅÂú®Âè∞ÁÅ£Âª∫ÈÄ†P4ÂØ¶È©óÂÆ§Ôºå‰ΩÜÂÖ∂Â∏≥ËôüÊú¨Ë∫´ÂèØÁñëÔºåÂõ†ÂÖ∂Â§ßÈ†≠Ë≤ºÈ°ØÁÇ∫ÁõúÁî®ÔºõÂÖ∂ÁôºÊñáÈÇÑË¢´ÊùéÂÄ©(Â∏≥ËôüÂêåÊ®£‰∏çÁúü)ÂàÜ‰∫´Âà∞15ÂÄãÂèçÁ∂†Èô£ÁáüÁ§æÂúòÔºåÂÖßÂÆπÂÆåÂÖ®Ë§áË£ΩÁõ∏ÂêåÔºåÈ°ØÈùû‰∏ÄËà¨Ëá™ÁÑ∂‰∫∫ÁöÑË°åÁÇ∫Ê®°Âºè(Pattern of Behavior)„ÄÇ Ê†πÊìö‰∏äËø∞Ë≥áÊñôÔºåÂèØ‰ª•ÁúãÂá∫Â¢ÉÂ§ñË≥áË®äÊìçÂºÑËàáÂπ≤È†ê(FIMI, Foreign Information Manipulation Interference)ÁöÑÁóïË∑°ÔºåÂÖ∂‰∏≠‰∏≤ËÅØ‰∫ÜË≠∞È°å„ÄÅË°åÂãïËÄÖ„ÄÅÂãïÊ©ü(Âà©Áõä)„ÄÅ‰ª•ÂèäË°åÂãïÂõõÂ§ßË¶ÅÁ¥†„ÄÇÈõñÁÑ∂ÂæÆÂçöÂ§ßVÈÇÑÈÄèÈÅéÊ®ôÁ±§Âä´ÊåÅ(Hashtag Hijacking)‰æÜÂê∏ÂºïÊ≥®ÊÑèÔºå‰ΩÜÈÄô‰∫ã‰ª∂Âú®Âè∞ÁÅ£‰∏ªÊµÅÁ§æÁæ§Âπ≥Âè∞‰∏äËÅ≤ÈáèÁõ∏Â∞ç‰∏çÈ´ò(Ëá≥Â§öÂú®‰∏≠Â§©Êñ∞ËÅû‰∏äÂÇ≥ÊñºYoutubeÁöÑÁØÄÁõÆÁâáÊÆµÊúâ5Ëê¨‰∫∫Ê¨°ËßÄÁúã)ÔºåË®éË´ñÂ∫¶ÁÜ±Â∫¶‰πü‰∏çÊåÅ‰πÖ„ÄÇ\nÊúâË∂£ÁöÑÊòØÔºå‰ªäÂπ¥8ÊúàÁæéÂúãÁñæÁóÖÁÆ°Âà∂ÂñÆ‰ΩçÂú®Âä†Â∑ûÁ†¥Áç≤‰∏ÄÈñìÈùûÊ≥ïÁîüÁâ©ÂØ¶È©óÂÆ§ÔºåÂÖ∂‰∏≠ÊúâÂØ¶È©óËÄÅÈº†„ÄÅÂåñÂ≠∏Ëó•ÂìÅÂèäÂ∏∂ÊúâÂÇ≥ÊüìÊ∫êÁöÑÁîüÁâ©ÊùêÊñô„ÄÇÈÄôËµ∑ÈùûÊ≥ïÂØ¶È©óÂÆ§ÁñëËàá‰∏≠ÂúãÊúâÈóúÔºåÂºïÁàÜÁæéÂúãÁöÑÂúãÂÆâÂç±Ê©üÔºåÂêåÊôÇ‰∫¶ÂèØÂÅöÁÇ∫„ÄåÂè∞ÁÅ£ÁîüÂåñÂØ¶È©óÂÆ§„ÄçË¨†Ë®ÄÁöÑÁúüÂØ¶Â∞çÈÄ†ÁµÑ„ÄÇ\nÁµêË™û ÈÄèÈÅéSCOTCHÊ°ÜÊû∂Ë™øÊü•ÁôºÁèæÔºåÂÖ©Â≤∏Â™íÈ´î‰ª•ÂèäÈùûÂúãÂÆ∂Ë°åÂãïËÄÖ‰ΩøÁî®Youtube„ÄÅFacebook„ÄÅX(Twitter)„ÄÅÂæÆÂçö„ÄÅTiktokÁ≠âÁ§æÁæ§Âπ≥Âè∞ÔºåÂºïÁî®Âè∞Â™íÁöÑÁç®ÂÆ∂Â†±Â∞éÂèäÂè∞ÁÅ£ÁöÑÂØ¶È©óÂÆ§Áõ∏ÈóúÂúñË≥áÔºåÈÄöÈÅéÊ®ôÁ±§Âä´ÊåÅ‰æÜÂê∏ÂºïÊ≥®ÊÑèÔºå‰ª•ÂèäÂú®ÊúâÂÖ±ÂêåÁêÜÂøµ(Shared-Interest)ÁöÑFacebookÁ§æÂúò‰∏≠Ë§áË£ΩË≤º‰∏äÂàÜ‰∫´Ë≤ºÊñá„ÄÇ Ë©¶ÂúñÂú®‰∏≠ÂúãÁæ§ÁúæÂèäÂè∞ÁÅ£ÂèçÂ∞çÊ∞ëÈÄ≤Èª®ÁöÑÁæ§Áúæ‰∏≠ÔºåÊ§çÂÖ•ÁæéÊñπÁ±≤Âè∞Âª∫ÈÄ†P4ÂØ¶È©óÂÆ§Á†îÁôºÁîüÁâ©Êà∞ÂäëÁöÑË¨†Ë®ÄÔºåÈÄôË¨†Ë®ÄÂ∏∂ÊúâÈÉ®ÂàÜÁúüÂØ¶ÊÄßÔºå‰ΩÜÊª≤ÂÖ•‰∏çÂØ¶Ë≥áË®äÊàñÈÅéÂ∫¶Ëß£ËÆÄÔºå‰ª•Ê§çÂÖ•Ê∞ëÈÄ≤Èª®ÊîøÂ∫úÁäßÁâ≤Ê∞ëÁúæÂÆâÂÖ®ÁöÑÁñëÁæéË´ñÔºå‰∏ç‰ΩÜÁ†¥Â£ûÂè∞ÁÅ£Ê∞ëÁúæÂ∞çÂúãÂÆ∂ÁîüÁâ©ÂÆâÂÖ®ÊîøÁ≠ñÁöÑ‰ø°‰ªªÔºå‰πü‰ª§‰∏≠ÂúãÁæ§ÁúæÊÑüÂèóÂà∞‰æÜËá™Âè∞ÁÅ£ÁöÑÁîüÂåñÂ®ÅËÑÖ„ÄÇ\nÊú¨Êñá‰ΩøÁî®ÁöÑÂ∑•ÂÖ∑ÂèäÂàÜÊûêÊñπÊ≥ïÊÑüË¨ùÂè∞ÁÅ£Ê∞ë‰∏ªÂØ¶È©óÂÆ§ÁöÑË™≤Á®ã„ÄÇ\nÊú¨ÊñáÂêåÊ≠•ÁôºË°®ÊñºMedium„ÄÇ\n","date":"2023-08-31T22:11:12+08:00","permalink":"https://haokaitseng.github.io/post/20230901%E5%8F%B0%E7%81%A3%E7%94%9F%E5%8C%96%E5%AF%A6%E9%A9%97%E5%AE%A4/","section":"post","tags":null,"title":"ÊúâÈóúÂè∞ÁÅ£ÁîüÂåñÂØ¶È©óÂÆ§ÁöÑÂ¢ÉÂ§ñË≥áË®äÊìçÂºÑËàáÂπ≤È†ê / A Case Study of Foreign Information Manipulation Interference: United States Asked Taiwan to Develop Weaponized Biological Agents in P4¬†Lab"},{"categories":["Essay"],"contents":"1. ÂÖ®ÁêÉÁ∏Ω‰∫∫Âè£Áï∂‰∏≠ÔºåÊúâ3.5%ÁöÑ‰∫∫ÊòØÁßªÂ∑•„ÄÇ‰ΩÜÂú®COVID-19(‰∏ãÁ®±Êñ∞ÂÜ†ËÇ∫ÁÇé)Á¢∫Ë®∫Êï∏ÊúÄÈ´òÁöÑ20ÂúãÁï∂‰∏≠ÔºåÁßªÂ∑•‰ΩîÂÖ∂Á∏Ω‰∫∫Âè£Êï∏Ëá≥Â∞ë4.5%ÔºåÈÄô‰∫õÁßªÂ∑•Âú®Áñ´ÊÉÖÁï∂‰∏≠Áõ∏Â∞çÂú∞Èù¢Ëá®Êõ¥È´òÁöÑÊÑüÊüìÈ¢®Èö™‰ª•ÂèäÁîüÂ≠òËÄÉÈ©ó„ÄÇ\nÊó©ÊñºÁñ´ÊÉÖ‰πãÂâçÔºåÁßªÂ∑•ÂÆπÊòìÊàêÁÇ∫Á§æÊúÉ‰∏≠ÁöÑÂº±Âã¢ÊóèÁæ§„ÄÇ‰ΩÜÁñ´ÊÉÖ‰ΩøÂæóÈÄôÁæ§‰∫∫Êõ¥ÁÇ∫ËÑÜÂº±ÔºåÂéüÂõ†ÂåÖÂê´ÈÇäÂ¢ÉÁöÑÂ∞ÅÈéñ„ÄÅÁî¢Ê•≠Á∑äÁ∏ÆÂ∞éËá¥ÁöÑÂ§±Ê•≠ÊàñÂãûÂãïÊ¢ù‰ª∂Âä£Âåñ„ÄÅÈõÜÈ´îÂºè(ÊòìÁæ§ËÅöÊÑüÊüì)ÁöÑ‰ΩèÊâÄ„ÄÅÂ∞çÂÅ•Â∫∑Ë≥áË®äÁöÑË™ûË®ÄË≠òËÆÄÈöúÁ§ô„ÄÅË∫´ÂàÜËÆäÂãïÈÄ†ÊàêÂú®Á§æÊúÉÂÆâÂÖ®Á∂≤ÈÇäÁ∑£ÂåñÊàñÊéíÈô§„ÄÅÈÇÑÊúâÂ∞çÂ§ñ‰æÜËÄÖÁöÑÊ≠ßË¶ñÁ≠âÁ≠â„ÄÇ\nÊàëÂÄëÂèØ‰ª•ÂæûË∑®Â¢ÉÂåØÊ¨æÁöÑÊ∂àÈï∑‰æÜÊÉ≥ÂÉèÁßªÂ∑•Á∂ìÊøüÂΩ±ÈüøÁöÑÁ®ãÂ∫¶„ÄÇÊ†πÊìö‰∏ñÁïåÈäÄË°åÂú®ÂéªÂπ¥ÂõõÊúàÁöÑÊé®‰º∞Ôºå2020Âπ¥ÂåØÂæÄ‰∏≠‰ΩéÊî∂ÂÖ•ÂúãÂÆ∂ÁöÑÊ¨æÈ†Ö‰º∞Ë®àËºÉÂéüÂÖàÈ†ê‰º∞ÈáëÈ°çÂ§ßÊ∏õ20%ÔºåÈõñÁÑ∂Âú®Âæå‰æÜ10ÊúàÁöÑÂ†±Âëä‰∏≠ÊúâÂ∞çÊ≠§ÊØî‰æã‰∏ãË™øÁÇ∫11%Ôºå‰ΩÜÈÄôÂπÖÂ∫¶ÈÇÑÊòØÁõ∏Áï∂È©ö‰∫∫Ôºå‰ª£Ë°®Ë®±Â§öÁßªÂ∑•Âá∫Â§ñÊâìÊãºÔºåÂçªÂèØËÉΩÂõ†ÁÇ∫Áñ´ÊÉÖÂ§±Ê•≠ÔºåË≥∫‰∏çÂ§†Èå¢ÂØÑÂõûËÄÅÂÆ∂‰æõÈ§ä„ÄÇ‰ΩÜÊúâ‰∫õ‰∏çÂ∞ãÂ∏∏ÁöÑÈáëÊµÅÔºå‰æãÂ¶ÇÂ∞ºÊ≥äÁàæÂú®‰∏ãÂçäÂπ¥Â∫¶Êî∂Âà∞ËºÉÂæÄÂπ¥Êõ¥Â§öÁöÑÂåØÊ¨æÔºåÊé®Ê∏¨ËàáÁï∂Âú∞Áñ´ÊÉÖÊõ¥Ë∂®Âö¥ÈáçÔºåÊµ∑Â§ñÂÆ∂‰∫∫Âä†Âº∑ÈáëÊè¥ÊúâÈóú„ÄÇ\nÂèóÂΩ±ÈüøÁöÑÈÇÑÊúâÂúãÈöõÁÖßÈ°ßÈçäÁöÑÊú´Á´Ø‚îÄ‚îÄÂ∑≤ÈñãÁôºÂúãÂÆ∂ÁöÑÂãûÂãïÂäõÈúÄÊ±Ç„ÄÇÊó•Êú¨ÁõÆÂâçÂõ†ÂÖ®Èù¢ÈéñÂúãÔºåÁáüÈÄ†Ê•≠ËàáÊúçÂãôÊ•≠ÁöÑ‰∫∫ÂäõÁü≠Áº∫Á´ãÂàªÊµÆÁèæÔºõÈüìÂúãÁöÑËæ≤Â∑•Á≠â‰πüÈù¢Ëá®Áü≠Áº∫ÔºåÂ∞§ÂÖ∂ÂÉèÂ≠£ÁØÄÊÄßÁßªÂ∑•ÂÆåÂÖ®ÁÑ°Ê≥ïÂÖ•Â¢ÉÔºåÂèçÂÄíËÆìÁèæÊúâÁöÑËæ≤Â∑•Êó•Ëñ™Êº≤‰∫ÜÂÖ©‰∏âÊàê„ÄÇ\nÊñºÊòØÂ†±Â∞éÂ∏∏Áî®stranded‰∏ÄË©ûÔºå‰æÜÂΩ¢ÂÆπÂú®Áñ´ÊÉÖ‰∏≠Â§ßË¶èÊ®°Êì±Ê∑∫ÁöÑÁßªÂ∑•Ôºå‰∏çË´ñÊòØÂú®‰∫∫Ë∫´Ëá™Áî±„ÄÅÊî∂ÂÖ•„ÄÅÊàñÊÄùÈÑâÁöÑÂøÉÊÉÖ‰∏ä„ÄÇ\n2. ‰ΩÜÂú®Ëá∫ÁÅ£‚îÄ‚îÄ‰∏ÄÂÄãÂ•Ω‰∏ÄÊÆµÊôÇÈñìË¢´Êñ∞ÂÜ†ÁóÖÊØíÈÅ∫ÂøòÁöÑÂ≥∂Â∂ºÔºåÈÄôË©ûËòäÂê´ÁöÑÊôØÊ≥ÅÂÖ®ÁÑ∂‰∏çÂêå„ÄÇ\nÊåáÊèÆ‰∏≠ÂøÉË°®Á§∫ÔºåÊ°à„Äá„Äá„ÄáÁÇ∫Âç∞Â∞ºÁ±ç20Â§öÊ≠≤Áî∑ÊÄßÔºå‰ªä(2020)Âπ¥„Äá„ÄáÊúà„Äá„ÄáÊó•‰æÜËá∫Â∑•‰Ωú(„Äá„Äá„Äá„Äá)ÔºåÊåÅÊúâÁôªÊ©üÂâç3Êó•ÂÖßÊ†∏ÈÖ∏Ê™¢È©óÈô∞ÊÄßÂ†±ÂëäÔºåÂÖ•Â¢ÉÂæåËá≥Èò≤Áñ´ÊóÖÈ§®ÈÄ≤Ë°åÂ±ÖÂÆ∂Ê™¢Áñ´ÔºåËøÑ‰ªäÁÑ°ÁóáÁãÄÔºõ„Äá„ÄáÊúà„ÄáÊó•Ê™¢Áñ´ÊúüÊªøÂæåÔºåÊê≠‰πòÂ∞àËªäËá≥ÂÖ∂‰ªñËôïÊâÄËá™‰∏ªÂÅ•Â∫∑ÁÆ°ÁêÜÔºå„Äá„ÄáÊúà„Äá„ÄáÊó•Áî±ÂÖ¨Âè∏ÂÆâÊéíËá™Ë≤ªÊé°Ê™¢ÔºåÊñº‰ªäÊó•Á¢∫Ë®∫(CtÂÄº„Äá„Äá)„ÄÇË°õÁîüÂñÆ‰ΩçÂ∑≤Âå°ÂàóÂÄãÊ°àÊé•Ëß∏ËÄÖÂÖ±„Äá‰∫∫ÔºåÂõ†ÊúâÈÅ©Áï∂Èò≤Ë≠∑ÔºåÂàóÁÇ∫Ëá™‰∏ªÂÅ•Â∫∑ÁÆ°ÁêÜ„ÄÇ\nÈÄôÊòØÊàë‰∏ÄÂÄãÁñ´Ë™øÂà∞ÂçäÂ§úÁöÑÂÄãÊ°àÔºåÊúÄÂæåÂú®Êñ∞ËÅûÁ®ø‰∏äÂëàÁèæÁöÑÊÆµËêΩ„ÄÇ‰∏çÁÇ∫‰∫∫Áü•ÁöÑÊòØÔºåÈÇ£‰∫õÂàóÁÇ∫Ëá™‰∏ªÂÅ•Â∫∑ÁÆ°ÁêÜÁöÑÊé•Ëß∏ËÄÖÔºåËàáÂÄãÊ°àÂêå‰∏ÄÊôÇÊúüÂÖ•Â¢ÉÔºå‰∏ÄËµ∑Êê≠ËªäÊé°Ê™¢ÔºåË∑üÂÄãÊ°à‰πüË™ûË®Ä‰∏çÈÄöÔºåÂæàÂø´Â∞±Ë¢´Â§ñÂïÜÂÖ¨Âè∏ÈÅ£ÈÄÅÂõûÂúã‰∫Ü„ÄÇÁï∂ÊôÇÊàëÈÄ£ÂøôË∑ü‰ª≤‰ªãËß£ÈáãÔºå‰ªñÂÄëÊúâËëóÂÖ•Â¢ÉÈô∞ÊÄß+14Â§©Ê™¢Áñ´+7Â§©Ëá™‰∏ªËá™Â∫∑ÁÆ°ÁêÜ+Âè£ÁΩ©+Ëá™Ë≤ªÈô∞ÊÄßÁöÑÈáëÁâåÔºåÊàëÂÄëÈò≤Áñ´‰∏¶Ê≤íÊúâÈúÄË¶ÅÂÅöÂà∞ÈÄôÂÄãÂú∞Ê≠•ÔºåÊúâÂÖ∂‰ªñ‰æãÂ¶ÇÂÜçÊ¨°Ëá™Ë≤ªÁöÑËæ¶Ê≥ï‰æÜËß£Ê±∫‚Ä¶„ÄÇ„ÄåÂÖ¨Âè∏ÂæàË¨πÊÖé„ÄçÔºå‰ª≤‰ªãÂè™ËÉΩÁÑ°Â•àÂú∞ÂõûÊáâ„ÄÇ\nÁõ∏ËºÉÊñºÊé•Ëß∏ËÄÖÊòØ‰∏çË¢´ÂÅúÁïôÁöÑ‰∫∫ÔºåÈÄô‰ΩçÂç∞Â∞ºÁî∑Â≠©ÂâáÊòØÂæπÂ∫ïÂú∞Ë¢´ÊªØÁïô‰∫Ü„ÄÇÂèóÈÅéÂ§ßÂ≠∏ÊïôËÇ≤ÁöÑ‰ªñÔºå‰æÜËá∫ÁÅ£Â∑•‰ΩúÊòØ‰ªñÂá∫Á§æÊúÉÂæåÁ¨¨‰∏Ä‰ªΩÂêàÁ¥ÑÔºåÊ™¢Áñ´/ÁÆ°ÁêÜÁ¥Ñ20Â§©ÂæåÔºåÂÜçÊé•‰∏ÄÂÄãÊúàÁöÑ‰ΩèÈô¢ÈöîÈõ¢Ôºå‰∏≠ÈÄîÊ≠∑Á∂ì‰∏ÄÂ∫¶Èô∞ÊÄßÂçªÈôΩËΩâÁöÑÁµïÊúõ„ÄÇÊúÄÁµÇÊåáÊèÆÂÆòÊ†∏ÂÆöËß£ÈöîÂæåÔºå‰ªñË°®Á§∫ÊÉ≥ÂõûÂÆ∂(ÂÖ¨Âè∏‰πü‰∏çÈ°òÁî®‰ªñ)Ôºå‰ΩÜÈÅé‰∫ÜÊï∏ÈÄ±‰ªçÁôª‰∏ç‰∏äÈ£õÊ©üÔºåÂõ†ÁÇ∫Êê≠Ê©üÈúÄË¶ÅÁöÑÊ†∏ÈÖ∏Èô∞ÊÄßÂ†±ÂëäÔºå‰ªñÂá∫Èô¢È©ó‰∫ÜÂÖ©Ê¨°ÈÇÑÊòØÁîü‰∏çÂá∫‰æÜ(ËºïÁóáËÄÖÂèØËÉΩÁóäÁôíÂæåÊï∏ÂÄãÊúà‰ªçÈ©óÂæóÂá∫ÁóÖÊØíÊ†∏ÈÖ∏)„ÄÇ\n‰ªñÂõ†ÁÇ∫ÈÇäÂ¢ÉÁÆ°Âà∂ÊîøÁ≠ñÊ≤íÊúâÈö®Êñ∞Áü•Ë™øÊï¥ÔºåÂ∞±ÈÄôÊ®£Ë¢´ÊåÅÁ∫åË¢´ËªüÁ¶ÅÂú®ÊóÖÈ§®ÔºåÊ≠§ÂàªÈÇÑÂú®Á≠âÂæÖÊàëÂÄëËàáÂç∞Â∞ºÂÆòÊñπÁöÑÂçîÂïÜÁµêÊûú„ÄÇÂè¶‰∏ÄÂÄãÂçîË™øÊàêÂäüÁöÑÊ°à‰æãÊòØÔºå‰∏Ä‰ΩçÁ¢∫Ë®∫ÁßªÂ∑•‰∫åÊé°Èô∞Âá∫Èô¢ÂæåÔºåÈúÄË¶ÅÂÅöÂ§ñÁ±çÁßªÂ∑•ÂÖ•Â¢ÉÂÅ•Ê™¢ÔºåÂçªË¢´Â§öÂÆ∂ÈÜ´Èô¢ÊãíÁµïÔºåÊúÄÂæåÊúâË≥¥ÊàëËÄÅÈóÜÂá∫Èù¢ÊâçÊúâÈÜ´Èô¢È°òÊÑèÂπ´Â•πÂÅöÂÅ•Ê™¢„ÄÇ\nÂ∞çÊñº‰ª≤‰ªãËÄåË®ÄÔºåÁßªÂ∑•Á∏±‰ΩøÊúâÊê≠Ê©üÂâçÈô∞ÊÄßÂ†±ÂëäÔºåÈÇÑÊòØËàáÂç±Èö™ÂäÉ‰∏äÁ≠âËôüÔºåÊ™¢Áñ´ÂÆåÈÇÑÂæóÂÖ¨Ë≤ª/Ëá™Ë≤ªÊé°Ê™¢ÊâçËÉΩÊîæÂøÉÔºõÂÜçÊ¨°Êé°Ê™¢ÁöÑÁßªÂ∑•Â∞±ÊòØÈáëÈõûÊØçÔºå‰ª≤‰ªãÊúÉËøΩÂïèÊàëÂÄëÂ†±ÂëäÁµêÊûúÔºåÊâçËÉΩË∂ïÂø´‰∫§Â∑•ÊäΩÊàêÔºõ‰ΩÜ‰∏ÄÊó¶ÈôΩÊÄßÔºåÁßªÂ∑•Â∞±Êàê‰∫ÜÊéÉÊääÊòüÔºå‰ª≤‰ªãÊúÉË¢´ËøΩÊÆ∫ÂÅöÁñ´Ë™ø(Âõ†ÁÇ∫Ë™ûË®Ä‰∏çÈÄöÈúÄ‰ª∞Ë≥¥ÁøªË≠ØËÄÅÂ∏´)ÔºåÂ•Ω‰∏ÄÈªû‰ª≤‰ªãÁöÑÊúÉÂú®ÂØíÊµÅÊôÇÈóúÂøÉÂêåÈÑâÁßªÂ∑•Á©øÂæóÂ§†‰∏çÂ§†ÊöñÔºåÂ∑Æ‰∏ÄÈªûÁöÑ‰ª≤‰ªãÂ∞±‰∏çËÅû‰∏çÂïèÔºåÊàñÊãíÁµïÁßªÂ∑•Âú®‰ΩèÈô¢ÊúüÈñìÊÉ≥Ë¶ÅÁöÑÈ°çÂ§ñÈ£≤È£üËä±Ë≤ªÔºåÁîöËá≥ÊúâÁßªÂ∑•Ë¢´‰ª≤‰ªãÁΩµÂì≠ÔºåË™™„ÄåÂ¶≥ÁÇ∫‰ªÄÈ∫ºË¶ÅÂ∏∂ÁóÖÊØí‰æÜËá∫ÁÅ£„Äç„ÄÇ\n„Äå(Á¢∫Ë®∫)ÈÄôÊ®£Ë™∞Êï¢Áî®Ôºü„ÄçÈÄôÂ∏∏ÊòØ‰ª≤‰ªãÊé•Âà∞Âô©ËÄóÁï∂‰∏ãÁöÑÁ¨¨‰∏ÄÂèçÊáâ„ÄÇ\nÂæû1992Âπ¥È†íÂ∏É\u0026lt;Â∞±Ê•≠ÊúçÂãôÊ≥ï\u0026gt;ÔºåËá∫ÁÅ£ÂºïÈÄ≤Áî¢Ê•≠ËàáÁ§æÁ¶èÈ°ûÁßªÂ∑•Âø´Êªø30Âπ¥Ôºå‰ΩÜÂõ†ÁÇ∫Ê¥ªÂãïÈ†òÂüüÈ°ØÊúâ‰∫§ÈõÜÔºå70Ëê¨ÁßªÂ∑•Â∞çË®±Â§öÊú¨Âú∞‰∫∫ËÄåË®ÄÊòØÈö±ÂΩ¢Êàñ(Âõ†ÁÇ∫ËÅΩ‰∏çÊáÇ)Âà∫ËÄ≥ÁöÑÂ≠òÂú®„ÄÇ\nÊòØÁñ´ÊÉÖËÆìÊΩõÂú®30Âπ¥ÁöÑÊ≠ßË¶ñÊµÆÁèæËàáËÆäË≥™„ÄÇÂæûÂéªÂπ¥Âπ¥Â∫ïÂõ†Âç∞Â∞ºÁßªÂ∑•‰ΩîÂ¢ÉÂ§ñÁßªÂÖ•ÁöÑÂ§ßÂÆóÔºåÊåáÊèÆ‰∏≠ÂøÉÂÆ£Â∏ÉÂÖ®Èù¢Êö´ÂÅúÂºïÈÄ≤Âç∞Â∞ºÁ±çÁßªÂ∑•ÔºåÁñ´ÊÉÖÊñ∞ËÅû‰∏ãÊñπÂ∞±Á∏ΩÊúÉÊúâË¶ÅÁßªÂ∑•ÊªæÂõûÊØçÂúã„ÄÅÂà•Â∏∂ÁóÖÊØí‰æÜÂè∞„ÄÅÂÅ•‰øù‰∏çË©≤Ë£úÂä©ÈÜ´ÁôÇË≤ªÁî®Á≠â‰ªáÂ§ñÁïôË®Ä„ÄÇÊàëÂÄë‰πüÂ∏∏Êé•Âà∞Ê∞ëÁúæÈô≥ÊÉÖÂì™Ë£°ÊúâÂ±ÖÊ™¢ÁöÑÁßªÂ∑•‰∫ÇË∑ëÔºåÊàñÊüêÂÖ¨ÁúæÂ†¥ÊâÄÊúâÁßªÂ∑•Áæ§ËÅöÔºåÊàñË™™ÁßªÂ∑•Â∞çÁ§æÂçÄÁöÑËÄÅ‰∫∫Â∞èÂ≠©ÂæàÂç±Èö™‰∫ë‰∫ë„ÄÇ\nÂè¶‰∏ÄÊñπÈù¢ÔºåÁñ´ÊÉÖ‰πüËÆìÁßªÂ∑•ÁöÑËÑÜÂº±ÊÄßÊúâÊâÄÂèçËΩâ„ÄÇÂõ†ÁÇ∫Ë®±Â§öËà™Áè≠ÂÅúÈ£õ„ÄÅÊ∏õÁè≠„ÄÅÊàñÊº≤ÂÉπÔºåËÅòÂÉ±ÊúüÊªøÈÄæÊúüÂ±ÖÁïôÁöÑÂ§ñÁ±çÁßªÂ∑•ÁÑ°Ê≥ïÈÅ£ÈÄÅÈõ¢Â¢ÉÔºåÂ∞éËá¥Êî∂ÂÆπ‰∏≠ÂøÉË¢´Êì†ÁàÜÔºåÂÜçÂä†‰∏äÊî∂ÂÆπÊõø‰ª£Êé™ÊñΩÔºåÈùûÊ≥ïÁßªÂ∑•‰æøÂèØ‰ª•Êö´ÊôÇÂêàÊ≥ïÂú∞ÊâìÈªëÂ∑•ÔºåÈªëÂ∏ÇËñ™Ë≥áÊ∞¥Êº≤ËàπÈ´ò„ÄÇËÄåÂúãÈöõÁÖßÈ°ßÈçäÁöÑÊñ∑Â±§ÔºåËÆìÊúâÈï∑ÁÖßÈúÄÊ±ÇÁöÑÂÆ∂Â∫≠ÊúâÈå¢‰πüÊâæÁÑ°Â∑•ÔºåÂºïÁôºÂÖ∂‰ªñÁ§æÊúÉÂïèÈ°å„ÄÇ\n3. Âú®ÂÇ≥Áµ±ÂÇ≥ÊüìÁóÖÈ†òÂüüÔºåËóçÈ†òÁßªÂ∑•Êú¨Â∞±ÊòØÊîøÂ∫úÂö¥Âä†Áõ£ÊéßÁöÑÂ∞çË±°„ÄÇÂÉèÊàëÂÄëÈÉ®ÈñÄÈúÄËä±Â§öÈÅî‰∏âÂàÜ‰πã‰∏ÄÁöÑ‰∫∫ÂäõÔºå‰ª•È´òÈ°çÁΩ∞Èç∞ËºîÂ∞é‰ª≤‰ªãË®òÂæóÂ§öÊ¨°ÁöÑÁßªÂ∑•ÂÆöÊúüÂÅ•Ê™¢Ôºå‰æÜÁØ©Ê™¢Âá∫ÂØÑÁîüËü≤„ÄÅÁµêÊ†∏ÁóÖÁ≠âÂ¢ÉÂ§ñÁßªÂÖ•ÂÇ≥ÊüìÁóÖÔºõÁèæÂõ†ÊáâÊñ∞ÂÜ†ËÇ∫ÁÇéÁñ´ÊÉÖÔºåÁñæÁÆ°ÁΩ≤ÊúâË£Ω‰ΩúÂ§öÂúãË™ûË®ÄÁ¥†ÊùêÁöÑÈò≤Áñ´ÂÆ£Â∞éÂìÅÔºåÈÇÑËàáÂãûÂãïÈÉ®ÂïüÂãïÊ≥∞„ÄÅË∂äÁ±çÁßªÂ∑•Ê™¢Áñ´ÊúüÊªøÁØ©Ê™¢Á≠âÂä†Âº∑Êé™ÊñΩ„ÄÇ\n‰ΩÜÈÄôÊ®£Â∞±Ë∂≥Â§†‰∫ÜÂóéÔºüÁßÅË™çÁÇ∫‰∏ÄÊó¶Ê°ÉÂúíÂÆà‰∏ç‰ΩèÔºåÁ§æÂçÄÈñãÂßãÊµÅË°åÔºåÂÖ©È°ûÁßªÂ∑•ÂèØËÉΩÊàêÁÇ∫ÂÇ≥Êí≠Âä†ÈÄüÂô®Ôºö‰∏ÄÊòØ‰ΩèÂúòÈ´îÂÆøËàçÁöÑÁî¢Ê•≠È°ûÁßªÂ∑•Ôºå‰∫åÊòØÁÑ°ÂêàÊ≥ïË∫´ÂàÜÁöÑÁßªÂ∑•„ÄÇ\nÊñ∞Âä†Âù°Â∞±ÊòØÁ¨¨‰∏ÄÈ°ûÁßªÂ∑•ÊàêÁÇ∫Áñ´ÊÉÖÁ†¥Âè£ÁöÑÂÄüÈëë„ÄÇÂéªÂπ¥4ÊúàÁàÜÁôºÁöÑÂ§ßË¶èÊ®°ÁßªÂ∑•ÂÆøËàçÁæ§ËÅöÊÑüÊüìÔºåÂ∞±ÊòØÂõ†ÁÇ∫ÂÆøËàçÁí∞Â¢ÉÈï∑ÊúüÂ£ÖÊì†‰∏ç‰∫∫ÊÄßÂåñÊâÄÂ∞éËá¥Ôºõ‰ªñÂÄëÊúÄÁµÇÂú®ÂéªÂπ¥12Êúà‰ª•Ê†∏ÈÖ∏ËàáË°ÄÊ∏ÖÊ™¢Ê∏¨Â§ßÈáèÁØ©Ê™¢ÁôºÁèæÔºåÁßªÂ∑•ÊóèÁæ§ÁöÑÊñ∞ÂÜ†ËÇ∫ÁÇéÁõõË°åÁéáÈ´òÈÅî47%(Áõ∏Áï∂Êñº1Ëê¨5ÂçÉ‰∫∫Á¢∫Ë®∫)ÔºåÂ∞çÊØî‰∏ÄËà¨Â∏ÇÊ∞ëÂÉÖ4ÂçÉÂ§öÁöÑÁ¢∫Ë®∫Êï∏ÔºåÂèØÁÇ∫Êá∏ÊÆä„ÄÇ‰ΩÜÂç±Ê©ü‰πüÂèØ‰ª•ÊòØËΩâÊ©üÔºåÊñ∞Âä†Âù°‰πüÂõ†ÁÇ∫Áñ´ÊÉÖÈñãÂßãÈáçË¶ñÂ§ñÁ±çÁßªÂ∑•ÁöÑÂ±Ö‰ΩèÁ©∫ÈñìÔºåË™øÊï¥‰ΩøÂÆøËàçÊàøÈñìÂ§ßÂ∞èËàáÂØÜÂ∫¶Á¨¶ÂêàÂúãÈöõÂãûÂãïÁµÑÁπîÁöÑË¶èÁØÑ„ÄÇ\nÁ¨¨‰∫åÈ°ûÁßªÂ∑•ÊõæÂú®ÂéªÂπ¥Áñ´ÁóÖÊø´Ëß¥ÊôÇÊàêÁÇ∫ÁÑ¶Èªû„ÄÇ‰∏Ä‰ΩçÈùûÊ≥ïÁöÑÁßªÂ∑•ÁúãË≠∑Âú®ÈÜ´Èô¢ÊüìÁñ´ÔºåÂºïÁôºÁõ∏ÈóúÈÉ®ÈñÄÂä†Âº∑Êü•Á∑ùÁöÑÂãï‰ΩúÔºå‰ΩÜÊúÄÂæåÊåáÊèÆÂÆòÂõ†Èò≤Áñ´ÈáèËÉΩÁöÑËÄÉÈáèÔºåÂèçÂ∞çÊéÉËï©ÈùûÊ≥ïÁúãË≠∑ËÄå‰ΩúÁΩ∑„ÄÇ\n‰∏äÂë®ÊâçÂâõÊé•Âà∞‰∏ÄÈÄöÈõá‰∏ªË™™ÂâõÊ™¢Áñ´ÂÆåÁöÑÁßªÂ∑•ÈÄÉË∑ëÁöÑÈõªË©±ÔºåÂïèÈÄôÊ®£ÊúÉ‰∏çÊúÉÈÄ†ÊàêÈò≤Áñ´ÊºèÊ¥ûÔºüÊàëÂè™ËÉΩË™™Êàë‰∏çÁü•ÈÅì„ÄÇ‰ΩÜÊàëÂÄëÊõ¥ÊáâË©≤ÈóúÂøÉÁöÑÊòØÁßªÂ∑•ÁÇ∫‰ªÄÈ∫ºÊúÉÈÄÉË∑ëÁöÑÁµêÊßãÂïèÈ°åÔºåÈÄôÈ°ØÁèæÊàëÂÄë‰øÆË®ÇË´∏Â§öÂãûÂãïÊîøÁ≠ñ‚îÄ‚îÄÂèñÊ∂àÁßªÂ∑•‰∏âÂπ¥Âá∫Âúã‰∏ÄÊó•„ÄÅÈõ∂‰ªòË≤ªÊîπÈù©„ÄÅÁõ¥ËÅòÁ≠âÔºå‰ªçÁÑ°Ê≥ïÊ†πÈô§‰ª≤‰ªãÈ´îÂà∂ÁöÑÂâùÂâä„ÄÇÂîØÊúâÈÄèÈÅéËÆìÈùûÊ≥ïÁßªÂ∑•(ÁÑ°Ë´ñÊòØÈÄÉË∑ëÊàñËÅòÊúüÊªøÂõû‰∏çÂéª)ÂèñÂæóÂêàÊ≥ïË∫´ÂàÜÔºåÊâçËÉΩ‰øÉ‰ΩøÁßªÂ∑•ÈáçÊñ∞Ë¢´ÁÆ°ÁêÜÔºåÈ°òÊÑèÈÄöÂ†±ËàáÊ™¢Áñ´„ÄÇ\n‰Ω†È°ò‰∏çÈ°òÊÑèÂëäË®¥Êàë‰Ω†ÁîüÈ´î‰∏çËàíÊúçÔºå‰∏î‰∏çÈ°ßÊÖÆÂù¶ÁôΩ‰πãÂæåÁöÑÂæåÊûúÂë¢Ôºü\n‰∏ÄÂÄãÈò≤Áñ´È´îÂà∂ÁöÑÊàêÂäüËàáÂê¶ÔºåÂ∞±Âú®ÊñºÂÆÉÂ∞çÂÖ∂ÊâÄÊúâÊàêÂì°ÁöÑÂèØ‰ø°Ë≥¥ÊÄß„ÄÇÁóÖÊØíÂÆø‰∏ª‰∏¶‰∏çÂàÜÁ®ÆÊóèËÜöËâ≤ÔºåÂõ†Ê≠§ÈÄô‰ø°Ë≥¥Á∂≤Áµ°ÊñáÂåñÁöÑÁ∂≠Ë≠∑Ôºå‰∏çÂÉÖÊòØÂãûÂãïÂñÆ‰Ωç„ÄÅ‰ª≤‰ªã„ÄÅÈõá‰∏ª‰ªñÂÄëÁöÑ‰∫ãÔºåÈÄô‰πüÊòØÊàëÂÄëÁöÑ‰∫ã„ÄÇ\nÊú¨Êñá‰∫¶ÂêåÊ≠•ÁôºË°®ÊñºMedium\n","date":"2021-02-01T22:11:12+08:00","permalink":"https://haokaitseng.github.io/post/20210201%E7%96%AB%E6%83%85%E4%B8%8B%E7%9A%84%E7%A7%BB%E5%B7%A5-%E6%B5%81%E9%9B%A2%E5%B0%8B%E5%B2%B8%E7%9A%84%E4%BA%BA/","section":"post","tags":null,"title":"Áñ´ÊÉÖ‰∏ãÁöÑÁßªÂ∑•ÔºåÊµÅÈõ¢Â∞ãÂ≤∏ÁöÑ‰∫∫ / Migrant Workers Are Displaced Under COVID-19 Pandemic"}]